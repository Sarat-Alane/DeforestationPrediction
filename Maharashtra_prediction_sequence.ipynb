{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nKezdbO-n31",
        "outputId": "09b2f9fc-edde-43d5-8a01-5578c5a4813e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.46.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting streamlit-folium\n",
            "  Downloading streamlit_folium-0.25.0-py3-none-any.whl.metadata (621 bytes)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: folium!=0.15.0,>=0.13 in /usr/local/lib/python3.11/dist-packages (from streamlit-folium) (0.19.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from streamlit-folium) (3.1.6)\n",
            "Requirement already satisfied: branca in /usr/local/lib/python3.11/dist-packages (from streamlit-folium) (0.8.1)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.43.0)\n",
            "Requirement already satisfied: xyzservices in /usr/local/lib/python3.11/dist-packages (from folium!=0.15.0,>=0.13->streamlit-folium) (2025.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->streamlit-folium) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.46.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading streamlit_folium-0.25.0-py3-none-any.whl (328 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m328.4/328.4 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit, streamlit-folium\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.46.0 streamlit-folium-0.25.0 watchdog-6.0.0\n"
          ]
        }
      ],
      "source": [
        "pip install streamlit streamlit-folium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1dprqz6IBr2I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2bff024-6520-4c65-d04d-1ee8661bcb71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-06-21 07:41:35.505 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import folium\n",
        "from streamlit_folium import st_folium\n",
        "import joblib\n",
        "import numpy as np\n",
        "import ee\n",
        "import datetime\n",
        "\n",
        "# --- Initialize Earth Engine ---\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project='ringed-trail-454308-d2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "l03j4LjHLbm4"
      },
      "outputs": [],
      "source": [
        "import geopandas as gpd\n",
        "import json\n",
        "from shapely.geometry import shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1WMdI7gf9t3r"
      },
      "outputs": [],
      "source": [
        "code='''\n",
        "import joblib\n",
        "import streamlit as st\n",
        "import folium\n",
        "from streamlit_folium import st_folium\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import datetime\n",
        "import ee\n",
        "from shapely.geometry import shape\n",
        "\n",
        "# Initialize Earth Engine\n",
        "ee.Initialize(project='ringed-trail-454308-d2')\n",
        "\n",
        "# Load trained ensemble model and scaler\n",
        "model = joblib.load(\"this_ensemble_model.pkl\")\n",
        "scaler = joblib.load(\"this_scaler.pkl\")\n",
        "\n",
        "# UI setup\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"üß† Deforestation Prediction Grid Map (Maharashtra Region)\")\n",
        "\n",
        "@st.cache_data\n",
        "def load_grid():\n",
        "    return gpd.read_file(\"Maharashtra_5x5km_Grid.geojson\")\n",
        "\n",
        "gdf = load_grid()\n",
        "gdf[\"predicted\"] = None\n",
        "\n",
        "# Toggle prediction color overlay\n",
        "enable_colors = st.checkbox(\"üü©üü• Show prediction color (green: forest, red: deforested)\", value=True)\n",
        "\n",
        "# Center map around Maharashtra\n",
        "m = folium.Map(location=[19.5, 74], zoom_start=7.5, control_scale=True)\n",
        "\n",
        "# Add grid cells with dynamic styling\n",
        "for _, row in gdf.iterrows():\n",
        "    pred = row[\"predicted\"]\n",
        "    fill = \"gray\"\n",
        "    if enable_colors and pred in [0, 1]:\n",
        "        fill = \"green\" if pred == 0 else \"red\"\n",
        "\n",
        "    folium.GeoJson(\n",
        "        row[\"geometry\"],\n",
        "        style_function=lambda x, fill_color=fill: {\n",
        "            \"fillColor\": fill_color,\n",
        "            \"color\": \"black\",\n",
        "            \"weight\": 0.5,\n",
        "            \"fillOpacity\": 0.6 if enable_colors else 0.1\n",
        "        }\n",
        "    ).add_to(m)\n",
        "\n",
        "st.markdown(\"### üìç Click on a grid cell to get deforestation prediction\")\n",
        "map_data = st_folium(m, height=600, width=900)\n",
        "\n",
        "if map_data.get(\"last_clicked\"):\n",
        "    click_point = shape({\n",
        "        \"type\": \"Point\",\n",
        "        \"coordinates\": [map_data[\"last_clicked\"][\"lng\"], map_data[\"last_clicked\"][\"lat\"]]\n",
        "    })\n",
        "\n",
        "    selected = gdf[gdf.geometry.contains(click_point)]\n",
        "    if selected.empty:\n",
        "        st.warning(\"‚ö†Ô∏è Click within a valid grid cell.\")\n",
        "    else:\n",
        "        cell_idx = selected.index[0]\n",
        "        cell = selected.iloc[0]\n",
        "        lon, lat = cell.geometry.centroid.x, cell.geometry.centroid.y\n",
        "        st.info(f\"üß≠ Selected Cell Center: ({lat:.4f}, {lon:.4f})\")\n",
        "\n",
        "        point = ee.Geometry.Point([lon, lat])\n",
        "        try:\n",
        "            end_date = datetime.datetime.now().date()\n",
        "            start_date = end_date - datetime.timedelta(days=30)\n",
        "\n",
        "            # NDVI & EVI\n",
        "            mod13 = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "                .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\n",
        "                .select([\"NDVI\", \"EVI\"]).mean()\n",
        "            ndvi = mod13.select(\"NDVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"NDVI\").getInfo()\n",
        "            evi = mod13.select(\"EVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"EVI\").getInfo()\n",
        "\n",
        "            # NDMI\n",
        "            def compute_ndmi(img):\n",
        "                return img.addBands(img.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).rename(\"NDMI\"))\n",
        "\n",
        "            ndmi_img = ee.ImageCollection(\"MODIS/061/MOD09GA\") \\\n",
        "                .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\n",
        "                .map(compute_ndmi).select(\"NDMI\").mean()\n",
        "            ndmi = ndmi_img.reduceRegion(ee.Reducer.mean(), point, 500).get(\"NDMI\").getInfo()\n",
        "\n",
        "            # Precipitation\n",
        "            precip = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\n",
        "                .filterDate(str(start_date), str(end_date)) \\\n",
        "                .select(\"precipitation\").sum().reduceRegion(ee.Reducer.mean(), point, 5000).get(\"precipitation\").getInfo()\n",
        "\n",
        "            # LST\n",
        "            lst_img = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\n",
        "                .filterDate(str(start_date), str(end_date)) \\\n",
        "                .select(\"LST_Day_1km\").mean()\n",
        "            lst = lst_img.multiply(0.02).subtract(273.15).reduceRegion(ee.Reducer.mean(), point, 1000).get(\"LST_Day_1km\").getInfo()\n",
        "\n",
        "            # Treecover (static or annual)\n",
        "            treecover_img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\n",
        "                .filterBounds(point).select(\"Percent_Tree_Cover\").mean()\n",
        "            treecover = treecover_img.reduceRegion(ee.Reducer.mean(), point, 250).get(\"Percent_Tree_Cover\").getInfo()\n",
        "\n",
        "            # Seasonal anomaly\n",
        "            month = end_date.month\n",
        "            # These would ideally come from precomputed monthly means\n",
        "            lst_season_mean = 30  # placeholder\n",
        "            precip_season_mean = 50  # placeholder\n",
        "            lst_anomaly = lst - lst_season_mean\n",
        "            precip_anomaly = precip - precip_season_mean\n",
        "\n",
        "            features = np.array([[evi, ndmi, lst_anomaly, precip_anomaly, treecover]])\n",
        "            scaled = scaler.transform(features)\n",
        "            pred = model.predict(scaled)[0]\n",
        "            label = \"Deforested\" if pred == 1 else \"Forest\"\n",
        "\n",
        "            gdf.at[cell_idx, \"predicted\"] = pred\n",
        "\n",
        "            st.success(f\"‚úÖ Prediction: {label}\")\n",
        "            st.markdown(\"üìä **Feature Summary**\")\n",
        "            st.table({\n",
        "                \"NDVI\": [round(ndvi, 4)],\n",
        "                \"EVI\": [round(evi, 4)],\n",
        "                \"NDMI\": [round(ndmi, 4)],\n",
        "                \"LST (¬∞C)\": [round(lst, 2)],\n",
        "                \"LST Anomaly\": [round(lst_anomaly, 2)],\n",
        "                \"Precipitation (mm)\": [round(precip, 2)],\n",
        "                \"Precip Anomaly\": [round(precip_anomaly, 2)],\n",
        "                \"Treecover\": [round(treecover, 1)]\n",
        "            })\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(\"‚ùå Error during prediction.\")\n",
        "            st.text(str(e))\n",
        "\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bRcY-1IaA7Be"
      },
      "outputs": [],
      "source": [
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write(code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTdq-_8EAT2r",
        "outputId": "87944af9-5a53-40d9-9cb4-d777b1df7781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.237.115.225\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8rEIXdLAXiU",
        "outputId": "13a47e72-496a-43fe-fb20-fa70cd6f4bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.115.225:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K\u001b[1G\u001b[0JNeed to install the following packages:\n",
            "localtunnel@2.0.2\n",
            "Ok to proceed? (y) \u001b[20Gy\n",
            "\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K‚†ã\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0Kyour url is: https://upset-snakes-hope.loca.lt\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/root/.npm/_npx/75ac80b86e83d4a2/node_modules/localtunnel/bin/lt.js:81\n",
            "    throw err;\n",
            "    ^\n",
            "\n",
            "Error: connection refused: localtunnel.me:14787 (check your firewall settings)\n",
            "    at Socket.<anonymous> (/root/.npm/_npx/75ac80b86e83d4a2/node_modules/\u001b[4mlocaltunnel\u001b[24m/lib/TunnelCluster.js:52:11)\n",
            "\u001b[90m    at Socket.emit (node:events:524:28)\u001b[39m\n",
            "\u001b[90m    at emitErrorNT (node:internal/streams/destroy:169:8)\u001b[39m\n",
            "\u001b[90m    at emitErrorCloseNT (node:internal/streams/destroy:128:3)\u001b[39m\n",
            "\u001b[90m    at process.processTicksAndRejections (node:internal/process/task_queues:82:21)\u001b[39m\n",
            "\n",
            "Node.js v20.19.0\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eaJkqyFdUGIm"
      },
      "outputs": [],
      "source": [
        "code2 = '''\n",
        "import joblib\n",
        "import streamlit as st\n",
        "import folium\n",
        "from streamlit_folium import st_folium\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import datetime\n",
        "import ee\n",
        "\n",
        "# Initialize Earth Engine\n",
        "ee.Initialize(project='ringed-trail-454308-d2')\n",
        "\n",
        "# Load trained ensemble model and scaler\n",
        "model = joblib.load(\"this_ensemble_model.pkl\")\n",
        "scaler = joblib.load(\"this_scaler.pkl\")\n",
        "\n",
        "# UI setup\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"üß† Deforestation Prediction Grid Map (Maharashtra Region)\")\n",
        "\n",
        "@st.cache_data\n",
        "def load_grid():\n",
        "    return gpd.read_file(\"Maharashtra_5x5km_Grid.geojson\")\n",
        "\n",
        "# üîÅ Limit to first 10 cells for faster testing\n",
        "gdf = load_grid().head(10)\n",
        "\n",
        "# Prediction date range\n",
        "end_date = datetime.datetime.now().date()\n",
        "start_date = end_date - datetime.timedelta(days=30)\n",
        "\n",
        "# Placeholder seasonal averages\n",
        "lst_season_mean = 30\n",
        "precip_season_mean = 50\n",
        "\n",
        "def compute_features(lon, lat):\n",
        "    point = ee.Geometry.Point([lon, lat])\n",
        "    try:\n",
        "        # NDVI & EVI\n",
        "        mod13 = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\\\n",
        "            .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\\\n",
        "            .select([\"NDVI\", \"EVI\"]).mean()\n",
        "        ndvi = mod13.select(\"NDVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"NDVI\").getInfo()\n",
        "        evi = mod13.select(\"EVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"EVI\").getInfo()\n",
        "\n",
        "        # NDMI\n",
        "        def add_ndmi(img):\n",
        "            return img.addBands(img.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).rename(\"NDMI\"))\n",
        "\n",
        "        ndmi_img = ee.ImageCollection(\"MODIS/061/MOD09GA\") \\\\\n",
        "            .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\\\n",
        "            .map(add_ndmi).select(\"NDMI\").mean()\n",
        "        ndmi = ndmi_img.reduceRegion(ee.Reducer.mean(), point, 500).get(\"NDMI\").getInfo()\n",
        "\n",
        "        # Precipitation\n",
        "        precip = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\\\n",
        "            .select(\"precipitation\").sum().reduceRegion(ee.Reducer.mean(), point, 5000).get(\"precipitation\").getInfo()\n",
        "\n",
        "        # LST\n",
        "        lst_img = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\\\n",
        "            .select(\"LST_Day_1km\").mean()\n",
        "        lst = lst_img.multiply(0.02).subtract(273.15).reduceRegion(ee.Reducer.mean(), point, 1000).get(\"LST_Day_1km\").getInfo()\n",
        "\n",
        "        # Treecover\n",
        "        tree_img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\\\n",
        "            .filterBounds(point).select(\"Percent_Tree_Cover\").mean()\n",
        "        treecover = tree_img.reduceRegion(ee.Reducer.mean(), point, 250).get(\"Percent_Tree_Cover\").getInfo()\n",
        "\n",
        "        lst_anomaly = lst - lst_season_mean\n",
        "        precip_anomaly = precip - precip_season_mean\n",
        "\n",
        "        return [evi, ndmi, lst_anomaly, precip_anomaly, treecover]\n",
        "    except:\n",
        "        return [None]*5\n",
        "\n",
        "st.info(\"‚è≥ Running prediction for first 10 grid cells...\")\n",
        "\n",
        "features_list = []\n",
        "for _, row in gdf.iterrows():\n",
        "    lon, lat = row.geometry.centroid.x, row.geometry.centroid.y\n",
        "    feats = compute_features(lon, lat)\n",
        "    if None not in feats:\n",
        "        features_list.append(feats)\n",
        "    else:\n",
        "        features_list.append([0]*5)  # fallback or skip\n",
        "\n",
        "X_scaled = scaler.transform(np.array(features_list))\n",
        "predictions = model.predict(X_scaled)\n",
        "gdf[\"predicted\"] = predictions\n",
        "\n",
        "enable_colors = st.checkbox(\"üü©üü• Show prediction color (green: forest, red: deforested)\", value=True)\n",
        "\n",
        "m = folium.Map(location=[19.5, 74], zoom_start=7.5, control_scale=True)\n",
        "\n",
        "for _, row in gdf.iterrows():\n",
        "    pred = row[\"predicted\"]\n",
        "    fill = \"gray\"\n",
        "    if enable_colors:\n",
        "        fill = \"green\" if pred == 0 else \"red\"\n",
        "\n",
        "    folium.GeoJson(\n",
        "        row[\"geometry\"],\n",
        "        style_function=lambda x, fill_color=fill: {\n",
        "            \"fillColor\": fill_color,\n",
        "            \"color\": \"black\",\n",
        "            \"weight\": 0.5,\n",
        "            \"fillOpacity\": 0.6 if enable_colors else 0.1\n",
        "        }\n",
        "    ).add_to(m)\n",
        "\n",
        "st.markdown(\"### üó∫Ô∏è Deforestation Prediction Map (First 10 Grids)\")\n",
        "st_folium(m, height=600, width=900)\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"app2.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(code2)\n"
      ],
      "metadata": {
        "id": "iEDQxYFdmVKb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8TxsbjmmYAy",
        "outputId": "0fe8aeae-3e01-4037-b12b-ed398b46c810"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.237.115.225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app2.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xpn5wx9vmcOo",
        "outputId": "f9b62dc9-3945-42af-a27c-198ebee3de40"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.115.225:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0Kyour url is: https://social-ears-train.loca.lt\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code3 = '''\n",
        "import joblib\n",
        "import streamlit as st\n",
        "import folium\n",
        "from streamlit_folium import st_folium\n",
        "from folium.plugins import Draw\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import datetime\n",
        "import ee\n",
        "from shapely.geometry import shape\n",
        "\n",
        "# Initialize Earth Engine\n",
        "ee.Initialize(project='ringed-trail-454308-d2')\n",
        "\n",
        "model = joblib.load(\"this_ensemble_model.pkl\")\n",
        "scaler = joblib.load(\"this_scaler.pkl\")\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"üß† Deforestation Prediction in Selected Region\")\n",
        "\n",
        "@st.cache_data\n",
        "def load_grid():\n",
        "    return gpd.read_file(\"Maharashtra_5x5km_Grid.geojson\")\n",
        "\n",
        "gdf = load_grid()\n",
        "gdf[\"predicted\"] = None\n",
        "\n",
        "st.info(\"‚úèÔ∏è Use the draw tool to select a region on the map\")\n",
        "\n",
        "m = folium.Map(location=[19.5, 74], zoom_start=7.5, control_scale=True)\n",
        "Draw(export=True).add_to(m)\n",
        "map_data = st_folium(m, height=600, width=900)\n",
        "\n",
        "if map_data.get(\"last_active_drawing\"):\n",
        "    drawn_geojson = map_data[\"last_active_drawing\"][\"geometry\"]\n",
        "    drawn_shape = shape(drawn_geojson)\n",
        "    selected_gdf = gdf[gdf.intersects(drawn_shape)]\n",
        "\n",
        "    if selected_gdf.empty:\n",
        "        st.warning(\"‚ö†Ô∏è No grid cells found in selected region.\")\n",
        "    else:\n",
        "        st.success(f\"üì¶ Selected {len(selected_gdf)} grid cells\")\n",
        "\n",
        "        # Dates\n",
        "        end_date = datetime.datetime.now().date()\n",
        "        start_date = end_date - datetime.timedelta(days=30)\n",
        "        lst_season_mean = 30\n",
        "        precip_season_mean = 50\n",
        "\n",
        "        def compute_features(lon, lat):\n",
        "            point = ee.Geometry.Point([lon, lat])\n",
        "            try:\n",
        "                mod13 = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\\\n",
        "                    .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\\\n",
        "                    .select([\"NDVI\", \"EVI\"]).mean()\n",
        "                ndvi = mod13.select(\"NDVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"NDVI\").getInfo()\n",
        "                evi = mod13.select(\"EVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"EVI\").getInfo()\n",
        "\n",
        "                def add_ndmi(img):\n",
        "                    return img.addBands(img.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).rename(\"NDMI\"))\n",
        "\n",
        "                ndmi_img = ee.ImageCollection(\"MODIS/061/MOD09GA\") \\\\\n",
        "                    .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\\\n",
        "                    .map(add_ndmi).select(\"NDMI\").mean()\n",
        "                ndmi = ndmi_img.reduceRegion(ee.Reducer.mean(), point, 500).get(\"NDMI\").getInfo()\n",
        "\n",
        "                precip = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\\\n",
        "                    .filterDate(str(start_date), str(end_date)) \\\\\n",
        "                    .select(\"precipitation\").sum().reduceRegion(ee.Reducer.mean(), point, 5000).get(\"precipitation\").getInfo()\n",
        "\n",
        "                lst_img = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\\\n",
        "                    .filterDate(str(start_date), str(end_date)) \\\\\n",
        "                    .select(\"LST_Day_1km\").mean()\n",
        "                lst = lst_img.multiply(0.02).subtract(273.15).reduceRegion(ee.Reducer.mean(), point, 1000).get(\"LST_Day_1km\").getInfo()\n",
        "\n",
        "                tree_img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\\\n",
        "                    .filterBounds(point).select(\"Percent_Tree_Cover\").mean()\n",
        "                treecover = tree_img.reduceRegion(ee.Reducer.mean(), point, 250).get(\"Percent_Tree_Cover\").getInfo()\n",
        "\n",
        "                lst_anomaly = lst - lst_season_mean\n",
        "                precip_anomaly = precip - precip_season_mean\n",
        "\n",
        "                return [evi, ndmi, lst_anomaly, precip_anomaly, treecover]\n",
        "            except:\n",
        "                return [None]*5\n",
        "\n",
        "        features_list = []\n",
        "        for _, row in selected_gdf.iterrows():\n",
        "            lon, lat = row.geometry.centroid.x, row.geometry.centroid.y\n",
        "            feats = compute_features(lon, lat)\n",
        "            if None not in feats:\n",
        "                features_list.append(feats)\n",
        "            else:\n",
        "                features_list.append([0]*5)\n",
        "\n",
        "        X_scaled = scaler.transform(np.array(features_list))\n",
        "        selected_gdf[\"predicted\"] = model.predict(X_scaled)\n",
        "\n",
        "        # Show map with colored grids\n",
        "        result_map = folium.Map(location=[19.5, 74], zoom_start=7.5, control_scale=True)\n",
        "        for _, row in selected_gdf.iterrows():\n",
        "            pred = row[\"predicted\"]\n",
        "            fill = \"green\" if pred == 0 else \"red\"\n",
        "            folium.GeoJson(\n",
        "                row[\"geometry\"],\n",
        "                style_function=lambda x, fill_color=fill: {\n",
        "                    \"fillColor\": fill_color,\n",
        "                    \"color\": \"black\",\n",
        "                    \"weight\": 0.5,\n",
        "                    \"fillOpacity\": 0.6\n",
        "                }\n",
        "            ).add_to(result_map)\n",
        "\n",
        "        st.markdown(\"### üó∫Ô∏è Predicted Deforestation Map for Selected Region\")\n",
        "        st_folium(result_map, height=600, width=900)\n",
        "else:\n",
        "    st.warning(\"üñ±Ô∏è Please draw a polygon on the map to select a region.\")\n",
        "'''\n"
      ],
      "metadata": {
        "id": "JonqMvN7mgAW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"app3.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(code3)\n"
      ],
      "metadata": {
        "id": "cEznqGWetyxT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Hh-tS-gt18y",
        "outputId": "97ea529b-d7a0-44e1-a433-057de000e9a0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.237.115.225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app3.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgB48AQ1t5SI",
        "outputId": "7d1316e8-09ea-4f89-96be-b8d446690973"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.115.225:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0Kyour url is: https://rude-mails-sniff.loca.lt\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/geopandas/geodataframe.py:1819: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  super().__setitem__(key, value)\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code4 = '''\n",
        "import joblib\n",
        "import streamlit as st\n",
        "import folium\n",
        "from streamlit_folium import st_folium\n",
        "from folium.plugins import Draw\n",
        "import numpy as np\n",
        "import geopandas as gpd\n",
        "import datetime\n",
        "import ee\n",
        "from shapely.geometry import shape\n",
        "\n",
        "# Initialize Earth Engine\n",
        "ee.Initialize(project='ringed-trail-454308-d2')\n",
        "\n",
        "model = joblib.load(\"this_ensemble_model.pkl\")\n",
        "scaler = joblib.load(\"this_scaler.pkl\")\n",
        "\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"üß† Deforestation Prediction in Selected Region\")\n",
        "\n",
        "@st.cache_data\n",
        "def load_grid():\n",
        "    return gpd.read_file(\"Maharashtra_5x5km_Grid.geojson\")\n",
        "\n",
        "gdf = load_grid()\n",
        "gdf[\"predicted\"] = None\n",
        "\n",
        "opacity = st.slider(\"üîÅ Set grid fill opacity\", 0.1, 1.0, 0.6, step=0.1)\n",
        "\n",
        "# Reset button\n",
        "if \"last_active_drawing\" in st.session_state:\n",
        "    if st.button(\"üîÑ Reset and Select New Region\"):\n",
        "        st.session_state.pop(\"last_active_drawing\")\n",
        "        st.rerun()\n",
        "\n",
        "# Show draw map if no selection\n",
        "if \"last_active_drawing\" not in st.session_state:\n",
        "    st.info(\"‚úèÔ∏è Use the draw tool to select a region on the map\")\n",
        "\n",
        "    m = folium.Map(location=[19.5, 74], zoom_start=7.5, control_scale=True)\n",
        "    Draw(export=True).add_to(m)\n",
        "    map_data = st_folium(m, height=600, width=900)\n",
        "\n",
        "    if map_data.get(\"last_active_drawing\"):\n",
        "        st.session_state[\"last_active_drawing\"] = map_data[\"last_active_drawing\"]\n",
        "        st.rerun()\n",
        "else:\n",
        "    drawn_geojson = st.session_state[\"last_active_drawing\"][\"geometry\"]\n",
        "    drawn_shape = shape(drawn_geojson)\n",
        "    selected_gdf = gdf[gdf.intersects(drawn_shape)].copy()\n",
        "\n",
        "    if selected_gdf.empty:\n",
        "        st.warning(\"‚ö†Ô∏è No grid cells found in selected region.\")\n",
        "    else:\n",
        "        st.success(f\"üì¶ Selected {len(selected_gdf)} grid cells\")\n",
        "\n",
        "        # Dates\n",
        "        end_date = datetime.datetime.now().date()\n",
        "        start_date = end_date - datetime.timedelta(days=30)\n",
        "        lst_season_mean = 30\n",
        "        precip_season_mean = 50\n",
        "\n",
        "        def compute_features(lon, lat):\n",
        "            point = ee.Geometry.Point([lon, lat])\n",
        "            try:\n",
        "                mod13 = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "                    .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\n",
        "                    .select([\"NDVI\", \"EVI\"]).mean()\n",
        "                ndvi = mod13.select(\"NDVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"NDVI\").getInfo()\n",
        "                evi = mod13.select(\"EVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"EVI\").getInfo()\n",
        "\n",
        "                def add_ndmi(img):\n",
        "                    return img.addBands(img.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).rename(\"NDMI\"))\n",
        "\n",
        "                ndmi_img = ee.ImageCollection(\"MODIS/061/MOD09GA\") \\\n",
        "                    .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\n",
        "                    .map(add_ndmi).select(\"NDMI\").mean()\n",
        "                ndmi = ndmi_img.reduceRegion(ee.Reducer.mean(), point, 500).get(\"NDMI\").getInfo()\n",
        "\n",
        "                precip = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\n",
        "                    .filterDate(str(start_date), str(end_date)) \\\n",
        "                    .select(\"precipitation\").sum().reduceRegion(ee.Reducer.mean(), point, 5000).get(\"precipitation\").getInfo()\n",
        "\n",
        "                lst_img = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\n",
        "                    .filterDate(str(start_date), str(end_date)) \\\n",
        "                    .select(\"LST_Day_1km\").mean()\n",
        "                lst = lst_img.multiply(0.02).subtract(273.15).reduceRegion(ee.Reducer.mean(), point, 1000).get(\"LST_Day_1km\").getInfo()\n",
        "\n",
        "                tree_img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\n",
        "                    .filterBounds(point).select(\"Percent_Tree_Cover\").mean()\n",
        "                treecover = tree_img.reduceRegion(ee.Reducer.mean(), point, 250).get(\"Percent_Tree_Cover\").getInfo()\n",
        "\n",
        "                lst_anomaly = lst - lst_season_mean\n",
        "                precip_anomaly = precip - precip_season_mean\n",
        "\n",
        "                return [evi, ndmi, lst_anomaly, precip_anomaly, treecover, ndvi]\n",
        "            except:\n",
        "                return [None]*6\n",
        "\n",
        "        features_list = []\n",
        "        param_data = []\n",
        "        valid_rows = []\n",
        "\n",
        "        for _, row in selected_gdf.iterrows():\n",
        "            lon, lat = row.geometry.centroid.x, row.geometry.centroid.y\n",
        "            feats = compute_features(lon, lat)\n",
        "            if None not in feats:\n",
        "                evi, ndmi, lst_anom, precip_anom, treecover, ndvi = feats\n",
        "                features_list.append([evi, ndmi, lst_anom, precip_anom, treecover])\n",
        "                param_data.append({\n",
        "                    \"NDVI\": round(ndvi, 4),\n",
        "                    \"EVI\": round(evi, 4),\n",
        "                    \"NDMI\": round(ndmi, 4),\n",
        "                    \"LST Anomaly\": round(lst_anom, 2),\n",
        "                    \"Precip Anomaly\": round(precip_anom, 2),\n",
        "                    \"Treecover\": round(treecover, 1)\n",
        "                })\n",
        "                valid_rows.append(row)\n",
        "\n",
        "        if not features_list:\n",
        "            st.error(\"‚ùå No valid data points found in selected region.\")\n",
        "        else:\n",
        "            valid_gdf = gpd.GeoDataFrame(valid_rows).reset_index(drop=True)\n",
        "            X_scaled = scaler.transform(np.array(features_list))\n",
        "            valid_gdf[\"predicted\"] = model.predict(X_scaled)\n",
        "\n",
        "            center_lat = valid_gdf.geometry.centroid.y.mean()\n",
        "            center_lon = valid_gdf.geometry.centroid.x.mean()\n",
        "\n",
        "            result_map = folium.Map(location=[center_lat, center_lon], zoom_start=9.5, control_scale=True)\n",
        "\n",
        "            for idx, row in valid_gdf.iterrows():\n",
        "                pred = row[\"predicted\"]\n",
        "                tooltip_text = \"<br>\".join([f\"{k}: {v}\" for k, v in param_data[idx].items()])\n",
        "                tooltip_text += \"<br>Prediction: \" + (\"Deforested\" if pred == 1 else \"Forest\")\n",
        "                fill = \"green\" if pred == 0 else \"red\"\n",
        "\n",
        "                folium.GeoJson(\n",
        "                    row[\"geometry\"],\n",
        "                    tooltip=tooltip_text,\n",
        "                    style_function=lambda x, fill_color=fill: {\n",
        "                        \"fillColor\": fill_color,\n",
        "                        \"color\": \"black\",\n",
        "                        \"weight\": 0.5,\n",
        "                        \"fillOpacity\": opacity\n",
        "                    }\n",
        "                ).add_to(result_map)\n",
        "\n",
        "            st.markdown(\"### üó∫Ô∏è Prediction Map for Selected Region\")\n",
        "            st_folium(result_map, height=600, width=900)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "Oen_fLXnt7w3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"app4.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(code4)"
      ],
      "metadata": {
        "id": "0zU16yGM8E1w"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtwsBEhP8MnD",
        "outputId": "0678489b-ae4a-4e57-9e75-b9bc17801340"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.237.115.225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app4.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i09-UXSU8Qg4",
        "outputId": "9e994b8f-79dd-4971-d073-4c09ddb3190f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.115.225:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0Kyour url is: https://honest-jars-relax.loca.lt\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code5 = '''\n",
        "# app.py\n",
        "import streamlit as st\n",
        "import folium\n",
        "from streamlit_folium import st_folium\n",
        "from folium.plugins import Draw\n",
        "import geopandas as gpd\n",
        "import datetime\n",
        "import numpy as np\n",
        "import joblib\n",
        "import ee\n",
        "from shapely.geometry import shape\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize EE\n",
        "ee.Initialize(project='ringed-trail-454308-d2')\n",
        "\n",
        "# Load model and scaler\n",
        "model = joblib.load(\"this_ensemble_model.pkl\")\n",
        "scaler = joblib.load(\"this_scaler.pkl\")\n",
        "\n",
        "# Load grid\n",
        "@st.cache_data\n",
        "def load_grid():\n",
        "    return gpd.read_file(\"Maharashtra_5x5km_Grid.geojson\")\n",
        "\n",
        "gdf = load_grid()\n",
        "\n",
        "# Streamlit setup\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"üå≥ Deforestation Analysis Tool\")\n",
        "\n",
        "page = st.sidebar.radio(\"üìÇ Navigation\", [\n",
        "    \"1Ô∏è‚É£ Visualize Environmental Layers\",\n",
        "    \"2Ô∏è‚É£ Predict Forest Cover\",\n",
        "    \"3Ô∏è‚É£ Timeline of Tree Cover\",\n",
        "    \"4Ô∏è‚É£ Environmental Statistics\"\n",
        "])\n",
        "\n",
        "# Reset feature\n",
        "if \"last_active_drawing\" in st.session_state:\n",
        "    if st.sidebar.button(\"üîÑ Reset Region\"):\n",
        "        st.session_state.pop(\"last_active_drawing\")\n",
        "        st.rerun()\n",
        "\n",
        "# Drawing map (common for all pages)\n",
        "if \"last_active_drawing\" not in st.session_state:\n",
        "    st.info(\"‚úèÔ∏è Draw a polygon to select a region\")\n",
        "\n",
        "    m = folium.Map(location=[19.5, 74], zoom_start=7.5)\n",
        "    Draw(export=True).add_to(m)\n",
        "    map_data = st_folium(m, height=600, width=900)\n",
        "\n",
        "    if map_data.get(\"last_active_drawing\"):\n",
        "        st.session_state[\"last_active_drawing\"] = map_data[\"last_active_drawing\"]\n",
        "        st.rerun()\n",
        "else:\n",
        "    # Selection geometry\n",
        "    drawn_geojson = st.session_state[\"last_active_drawing\"][\"geometry\"]\n",
        "    drawn_shape = shape(drawn_geojson)\n",
        "    selected_gdf = gdf[gdf.intersects(drawn_shape)].copy()\n",
        "\n",
        "    if selected_gdf.empty:\n",
        "        st.warning(\"‚ö†Ô∏è No grid found in selected region.\")\n",
        "    else:\n",
        "        st.success(f\"üìç Selected {len(selected_gdf)} grid cells\")\n",
        "\n",
        "        # Shared function to compute environmental features\n",
        "        def compute_features(lon, lat, start_date, end_date):\n",
        "            point = ee.Geometry.Point([lon, lat])\n",
        "            try:\n",
        "                mod13 = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "                    .filterDate(str(start_date), str(end_date)) \\\n",
        "                    .filterBounds(point) \\\n",
        "                    .select([\"NDVI\", \"EVI\"]).mean()\n",
        "\n",
        "                evi = mod13.select(\"EVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"EVI\").getInfo()\n",
        "                ndvi = mod13.select(\"NDVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"NDVI\").getInfo()\n",
        "\n",
        "                def add_ndmi(img):\n",
        "                    return img.addBands(img.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).rename(\"NDMI\"))\n",
        "\n",
        "                ndmi_img = ee.ImageCollection(\"MODIS/061/MOD09GA\") \\\n",
        "                    .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\n",
        "                    .map(add_ndmi).select(\"NDMI\").mean()\n",
        "                ndmi = ndmi_img.reduceRegion(ee.Reducer.mean(), point, 500).get(\"NDMI\").getInfo()\n",
        "\n",
        "                precip = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\n",
        "                    .filterDate(str(start_date), str(end_date)) \\\n",
        "                    .filterBounds(point).sum().select(\"precipitation\") \\\n",
        "                    .reduceRegion(ee.Reducer.mean(), point, 5000).get(\"precipitation\").getInfo()\n",
        "\n",
        "                lst_img = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\n",
        "                    .filterDate(str(start_date), str(end_date)) \\\n",
        "                    .filterBounds(point).select(\"LST_Day_1km\").mean()\n",
        "                lst = lst_img.multiply(0.02).subtract(273.15).reduceRegion(ee.Reducer.mean(), point, 1000).get(\"LST_Day_1km\").getInfo()\n",
        "\n",
        "                tree_img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\n",
        "                    .filterBounds(point).select(\"Percent_Tree_Cover\").mean()\n",
        "                treecover = tree_img.reduceRegion(ee.Reducer.mean(), point, 250).get(\"Percent_Tree_Cover\").getInfo()\n",
        "\n",
        "                return [evi, ndvi, ndmi, lst, precip, treecover]\n",
        "            except:\n",
        "                return [None]*6\n",
        "\n",
        "        if page == \"1Ô∏è‚É£ Visualize Environmental Layers\":\n",
        "            layer = st.selectbox(\"üìå Select layer to visualize\", [\"Tree Cover\", \"Precipitation\", \"Temperature (LST)\"])\n",
        "\n",
        "            # Determine image to use\n",
        "            end_date = datetime.date.today()\n",
        "            start_date = end_date - datetime.timedelta(days=30)\n",
        "            region = ee.Geometry.Polygon([list(drawn_shape.exterior.coords)])\n",
        "\n",
        "            if layer == \"Tree Cover\":\n",
        "                img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\n",
        "                    .filterBounds(region).select(\"Percent_Tree_Cover\").mean()\n",
        "                vis = {\"min\": 0, \"max\": 100, \"palette\": ['#f7fcf5','#e5f5e0','#a1d99b','#31a354','#006d2c']}\n",
        "                label = \"Tree Cover (%)\"\n",
        "            elif layer == \"Precipitation\":\n",
        "                img = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\n",
        "                    .filterDate(str(start_date), str(end_date)) \\\n",
        "                    .filterBounds(region).sum().select(\"precipitation\")\n",
        "                vis = {\"min\": 0, \"max\": 200, \"palette\": ['#f7fcf0', '#ccece6', '#66c2a4', '#238b45', '#005824']}\n",
        "                label = \"Precipitation (mm)\"\n",
        "            else:\n",
        "                img = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\n",
        "                    .filterDate(str(start_date), str(end_date)) \\\n",
        "                    .filterBounds(region).select(\"LST_Day_1km\").mean() \\\n",
        "                    .multiply(0.02).subtract(273.15)\n",
        "                vis = {\"min\": 10, \"max\": 45, \"palette\": ['#ffffb2','#fecc5c','#fd8d3c','#f03b20','#bd0026']}\n",
        "                label = \"LST (¬∞C)\"\n",
        "\n",
        "            m = folium.Map(location=[19.5, 74], zoom_start=8)\n",
        "            folium.raster_layers.TileLayer(\n",
        "                tiles=img.visualize(**vis).getMapId()[\"tile_fetcher\"].url_format,\n",
        "                attr=\"EE\", name=label, overlay=True, control=True\n",
        "            ).add_to(m)\n",
        "            folium.LayerControl().add_to(m)\n",
        "\n",
        "            st.markdown(f\"### üó∫Ô∏è {label} over selected region\")\n",
        "            st_folium(m, height=600, width=900)\n",
        "\n",
        "        elif page == \"2Ô∏è‚É£ Predict Forest Cover\":\n",
        "            st.markdown(\"### üîç Forest Prediction Map\")\n",
        "\n",
        "            features = []\n",
        "            for _, row in selected_gdf.iterrows():\n",
        "                lon, lat = row.geometry.centroid.x, row.geometry.centroid.y\n",
        "                feats = compute_features(lon, lat, datetime.date.today() - datetime.timedelta(days=30), datetime.date.today())\n",
        "                if None not in feats:\n",
        "                    features.append((row, feats))\n",
        "\n",
        "            if features:\n",
        "                X = [f[1][[0,2,3,4,5]] for f in features]  # drop NDVI\n",
        "                X_scaled = scaler.transform(X)\n",
        "                preds = model.predict(X_scaled)\n",
        "\n",
        "                m = folium.Map(location=[19.5, 74], zoom_start=8)\n",
        "                for idx, (row, _) in enumerate(features):\n",
        "                    fill_color = \"green\" if preds[idx] == 0 else \"red\"\n",
        "                    folium.GeoJson(row.geometry, style_function=lambda x, c=fill_color: {\n",
        "                        \"fillColor\": c, \"color\": \"black\", \"weight\": 1, \"fillOpacity\": 0.5\n",
        "                    }).add_to(m)\n",
        "\n",
        "                st_folium(m, height=600, width=900)\n",
        "            else:\n",
        "                st.warning(\"‚ö†Ô∏è No valid data found for prediction.\")\n",
        "\n",
        "        elif page == \"3Ô∏è‚É£ Timeline of Tree Cover\":\n",
        "            st.markdown(\"### ‚è≥ Tree Cover Timeline (2016‚Äì2025)\")\n",
        "\n",
        "            years = list(range(2016, 2027))  # Try including 2026\n",
        "            timeline_data = []\n",
        "\n",
        "            for y in years:\n",
        "                img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\n",
        "                    .filterDate(f\"{y}-01-01\", f\"{y}-12-31\") \\\n",
        "                    .filterBounds(region) \\\n",
        "                    .select(\"Percent_Tree_Cover\").mean()\n",
        "                mean_val = img.reduceRegion(ee.Reducer.mean(), region, 250).get(\"Percent_Tree_Cover\").getInfo()\n",
        "                if mean_val:\n",
        "                    timeline_data.append((y, round(mean_val, 2)))\n",
        "\n",
        "            df = pd.DataFrame(timeline_data, columns=[\"Year\", \"Mean Tree Cover\"])\n",
        "            st.line_chart(df.set_index(\"Year\"))\n",
        "\n",
        "        elif page == \"4Ô∏è‚É£ Environmental Statistics\":\n",
        "            st.markdown(\"### üìä Environmental Stats (2015‚Äì2023)\")\n",
        "\n",
        "            stats_data = []\n",
        "            for y in range(2015, 2024):\n",
        "                start = ee.Date.fromYMD(y, 1, 1)\n",
        "                end = start.advance(1, 'year')\n",
        "                for param, ic, band, scale in [\n",
        "                    (\"NDVI\", \"MODIS/061/MOD13Q1\", \"NDVI\", 250),\n",
        "                    (\"EVI\", \"MODIS/061/MOD13Q1\", \"EVI\", 250),\n",
        "                    (\"LST\", \"MODIS/061/MOD11A1\", \"LST_Day_1km\", 1000),\n",
        "                    (\"Precipitation\", \"UCSB-CHG/CHIRPS/DAILY\", \"precipitation\", 5000)\n",
        "                ]:\n",
        "                    img = ee.ImageCollection(ic).filterDate(start, end).filterBounds(region).select(band).mean()\n",
        "                    if band == \"LST_Day_1km\":\n",
        "                        img = img.multiply(0.02).subtract(273.15)\n",
        "                    elif band in [\"NDVI\", \"EVI\"]:\n",
        "                        img = img.multiply(0.0001)\n",
        "                    elif band == \"precipitation\":\n",
        "                        img = ee.ImageCollection(ic).filterDate(start, end).filterBounds(region).select(band).sum()\n",
        "\n",
        "                    val = img.reduceRegion(ee.Reducer.mean(), region, scale).get(band).getInfo()\n",
        "                    if val:\n",
        "                        stats_data.append({\"Year\": y, \"Parameter\": param, \"Value\": round(val, 3)})\n",
        "\n",
        "            df = pd.DataFrame(stats_data)\n",
        "            for param in df[\"Parameter\"].unique():\n",
        "                subset = df[df[\"Parameter\"] == param].set_index(\"Year\")\n",
        "                st.line_chart(subset[\"Value\"], height=250, use_container_width=True)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "wH0SV8bn8TbG"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"app5.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(code5)"
      ],
      "metadata": {
        "id": "_kDNpooGT62e"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS-POxEjT-xS",
        "outputId": "6a89610f-a4ff-4a32-e58a-705f6ea6e1c5"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.237.115.225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app5.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "FdPxzZdDUH0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "code6 = '''\n",
        "import streamlit as st\n",
        "import folium\n",
        "from streamlit_folium import st_folium\n",
        "from folium.plugins import Draw\n",
        "import geopandas as gpd\n",
        "import datetime\n",
        "import numpy as np\n",
        "import joblib\n",
        "import ee\n",
        "from shapely.geometry import shape\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize EE\n",
        "ee.Initialize(project='ringed-trail-454308-d2')\n",
        "\n",
        "# Load model and scaler\n",
        "model = joblib.load(\"this_ensemble_model.pkl\")\n",
        "scaler = joblib.load(\"this_scaler.pkl\")\n",
        "\n",
        "# Load grid\n",
        "@st.cache_data\n",
        "def load_grid():\n",
        "    return gpd.read_file(\"Maharashtra_5x5km_Grid.geojson\")\n",
        "\n",
        "gdf = load_grid()\n",
        "\n",
        "# Streamlit setup\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"üå≥ Deforestation Analysis Tool\")\n",
        "\n",
        "# Navigation menu\n",
        "page = st.sidebar.radio(\"üìÇ Navigation\", [\n",
        "    \"üåç Region Selection\",\n",
        "    \"1Ô∏è‚É£ Visualize Environmental Layers\",\n",
        "    \"2Ô∏è‚É£ Predict Forest Cover\",\n",
        "    \"3Ô∏è‚É£ Timeline of Tree Cover\",\n",
        "    \"4Ô∏è‚É£ Environmental Statistics\"\n",
        "])\n",
        "\n",
        "# Page 0: Region Selection\n",
        "if page == \"üåç Region Selection\":\n",
        "    st.header(\"‚úèÔ∏è Draw a Region to Analyze\")\n",
        "    m = folium.Map(location=[19.5, 74], zoom_start=7.5)\n",
        "    Draw(export=True).add_to(m)\n",
        "    map_data = st_folium(m, height=600, width=900)\n",
        "\n",
        "    if map_data.get(\"last_active_drawing\"):\n",
        "        st.session_state[\"last_active_drawing\"] = map_data[\"last_active_drawing\"]\n",
        "        st.success(\"‚úÖ Region Selected! Now switch pages from the left sidebar.\")\n",
        "\n",
        "    st.stop()\n",
        "\n",
        "# Reset\n",
        "if st.sidebar.button(\"üîÑ Reset Region\"):\n",
        "    st.session_state.pop(\"last_active_drawing\", None)\n",
        "    st.rerun()\n",
        "\n",
        "if \"last_active_drawing\" not in st.session_state:\n",
        "    st.warning(\"‚ö†Ô∏è Please go to 'Region Selection' and draw a region first.\")\n",
        "    st.stop()\n",
        "\n",
        "# Selected region\n",
        "drawn_shape = shape(st.session_state[\"last_active_drawing\"][\"geometry\"])\n",
        "selected_gdf = gdf[gdf.intersects(drawn_shape)].copy()\n",
        "region = ee.Geometry.Polygon([list(drawn_shape.exterior.coords)])\n",
        "\n",
        "if selected_gdf.empty:\n",
        "    st.warning(\"‚ö†Ô∏è No grid found in selected region.\")\n",
        "    st.stop()\n",
        "\n",
        "# ------------------ Helper: Compute EE features ------------------\n",
        "def compute_features(lon, lat, start_date, end_date):\n",
        "    point = ee.Geometry.Point([lon, lat])\n",
        "    try:\n",
        "        mod13 = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(point) \\\n",
        "            .select([\"NDVI\", \"EVI\"]).mean()\n",
        "\n",
        "        evi = mod13.select(\"EVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"EVI\").getInfo()\n",
        "        ndvi = mod13.select(\"NDVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"NDVI\").getInfo()\n",
        "\n",
        "        def add_ndmi(img):\n",
        "            return img.addBands(img.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).rename(\"NDMI\"))\n",
        "\n",
        "        ndmi_img = ee.ImageCollection(\"MODIS/061/MOD09GA\") \\\n",
        "            .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\n",
        "            .map(add_ndmi).select(\"NDMI\").mean()\n",
        "        ndmi = ndmi_img.reduceRegion(ee.Reducer.mean(), point, 500).get(\"NDMI\").getInfo()\n",
        "\n",
        "        precip = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(point).sum().select(\"precipitation\") \\\n",
        "            .reduceRegion(ee.Reducer.mean(), point, 5000).get(\"precipitation\").getInfo()\n",
        "\n",
        "        lst_img = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(point).select(\"LST_Day_1km\").mean()\n",
        "        lst = lst_img.multiply(0.02).subtract(273.15).reduceRegion(ee.Reducer.mean(), point, 1000).get(\"LST_Day_1km\").getInfo()\n",
        "\n",
        "        tree_img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\n",
        "            .filterBounds(point).select(\"Percent_Tree_Cover\").mean()\n",
        "        treecover = tree_img.reduceRegion(ee.Reducer.mean(), point, 250).get(\"Percent_Tree_Cover\").getInfo()\n",
        "\n",
        "        return [evi, ndvi, ndmi, lst, precip, treecover]\n",
        "    except:\n",
        "        return [None]*6\n",
        "\n",
        "# ------------------ Page 1 ------------------\n",
        "if page == \"1Ô∏è‚É£ Visualize Environmental Layers\":\n",
        "    st.header(\"üåç Environmental Layers Viewer\")\n",
        "    layer = st.selectbox(\"Select parameter to view\", [\n",
        "        \"Tree Cover\", \"Precipitation\", \"LST (Temp)\", \"NDVI\", \"EVI\", \"NDMI\"\n",
        "    ])\n",
        "    opacity = st.slider(\"üîÅ Layer Opacity\", 0.1, 1.0, 0.6)\n",
        "\n",
        "    end_date = datetime.date.today()\n",
        "    start_date = end_date - datetime.timedelta(days=30)\n",
        "\n",
        "    if layer == \"Tree Cover\":\n",
        "        img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\n",
        "            .filterBounds(region).select(\"Percent_Tree_Cover\").mean()\n",
        "        vis = {\"min\": 0, \"max\": 100, \"palette\": ['#f7fcf5','#e5f5e0','#a1d99b','#31a354','#006d2c']}\n",
        "    elif layer == \"Precipitation\":\n",
        "        img = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(region).sum().select(\"precipitation\")\n",
        "        vis = {\"min\": 0, \"max\": 200, \"palette\": ['#f7fcf0', '#ccece6', '#66c2a4', '#238b45', '#005824']}\n",
        "    elif layer == \"LST (Temp)\":\n",
        "        img = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(region).select(\"LST_Day_1km\").mean() \\\n",
        "            .multiply(0.02).subtract(273.15)\n",
        "        vis = {\"min\": 10, \"max\": 45, \"palette\": ['#ffffb2','#fecc5c','#fd8d3c','#f03b20','#bd0026']}\n",
        "    elif layer == \"NDVI\":\n",
        "        img = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(region).select(\"NDVI\").mean().multiply(0.0001)\n",
        "        vis = {\"min\": 0, \"max\": 1, \"palette\": ['#f7fcf5', '#00441b']}\n",
        "    elif layer == \"EVI\":\n",
        "        img = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(region).select(\"EVI\").mean().multiply(0.0001)\n",
        "        vis = {\"min\": 0, \"max\": 1, \"palette\": ['#f7fcf5', '#084081']}\n",
        "    else:  # NDMI\n",
        "        def add_ndmi(img):\n",
        "            return img.addBands(img.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).rename(\"NDMI\"))\n",
        "        img = ee.ImageCollection(\"MODIS/061/MOD09GA\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(region).map(add_ndmi).select(\"NDMI\").mean()\n",
        "        vis = {\"min\": -1, \"max\": 1, \"palette\": ['#67001f', '#f7f7f7', '#053061']}\n",
        "\n",
        "    mapid = img.visualize(**vis).getMapId()\n",
        "    tile_url = mapid[\"tile_fetcher\"].url_format\n",
        "\n",
        "    m = folium.Map(location=[19.5, 74], zoom_start=8)\n",
        "    folium.raster_layers.TileLayer(tiles=tile_url, name=layer, opacity=opacity, attr=\"Map data ¬© Google Earth Engine\").add_to(m)\n",
        "    st_folium(m, height=600, width=900)\n",
        "\n",
        "# ------------------ Page 2 ------------------\n",
        "if page == \"2Ô∏è‚É£ Predict Forest Cover\":\n",
        "    st.header(\"üß† Forest Cover Prediction\")\n",
        "    st.info(f\"Selected {len(selected_gdf)} grid cells for prediction.\")\n",
        "\n",
        "    end_date = datetime.date.today()\n",
        "    start_date = end_date - datetime.timedelta(days=30)\n",
        "\n",
        "    features = []\n",
        "    for _, row in selected_gdf.iterrows():\n",
        "        lon, lat = row.geometry.centroid.x, row.geometry.centroid.y\n",
        "        feats = compute_features(lon, lat, start_date, end_date)\n",
        "        features.append((row[\"geometry\"], feats))\n",
        "\n",
        "    X = [[f[1][i] for i in [0, 2, 3, 4, 5]] if None not in f[1] else [0]*5 for f in features]  # Drop NDVI\n",
        "    param_data = [{\n",
        "        \"EVI\": round(f[1][0], 4) if f[1][0] is not None else \"N/A\",\n",
        "        \"NDMI\": round(f[1][2], 4) if f[1][2] is not None else \"N/A\",\n",
        "        \"LST Anomaly\": round(f[1][3] - 30, 2) if f[1][3] is not None else \"N/A\",\n",
        "        \"Precip Anomaly\": round(f[1][4] - 50, 2) if f[1][4] is not None else \"N/A\",\n",
        "        \"Tree Cover\": round(f[1][5], 1) if f[1][5] is not None else \"N/A\"\n",
        "    } for f in features]\n",
        "\n",
        "    X_scaled = scaler.transform(np.array(X))\n",
        "    y_pred = model.predict(X_scaled)\n",
        "\n",
        "    center_lat = selected_gdf.geometry.centroid.y.mean()\n",
        "    center_lon = selected_gdf.geometry.centroid.x.mean()\n",
        "    opacity = st.slider(\"üñåÔ∏è Prediction Fill Opacity\", 0.1, 1.0, 0.6)\n",
        "\n",
        "    result_map = folium.Map(location=[center_lat, center_lon], zoom_start=9.5)\n",
        "\n",
        "    for idx, (geom, pred) in enumerate(zip([f[0] for f in features], y_pred)):\n",
        "        tooltip_text = \"<br>\".join([f\"{k}: {v}\" for k, v in param_data[idx].items()])\n",
        "        tooltip_text += \"<br><b>Prediction</b>: \" + (\"üå≥ Forest\" if pred == 0 else \"ü™µ Deforested\")\n",
        "        fill = \"green\" if pred == 0 else \"red\"\n",
        "\n",
        "        folium.GeoJson(\n",
        "            geom,\n",
        "            tooltip=tooltip_text,\n",
        "            style_function=lambda x, fill_color=fill: {\n",
        "                \"fillColor\": fill_color,\n",
        "                \"color\": \"black\",\n",
        "                \"weight\": 0.5,\n",
        "                \"fillOpacity\": opacity\n",
        "            }\n",
        "        ).add_to(result_map)\n",
        "\n",
        "    st.subheader(\"üó∫Ô∏è Predicted Forest Cover\")\n",
        "    st_folium(result_map, height=600, width=900)\n",
        "\n",
        "\n",
        "# ------------------ Page 3 ------------------\n",
        "if page == \"3Ô∏è‚É£ Timeline of Tree Cover\":\n",
        "    st.header(\"üìà Tree Cover Timeline (2016‚Äì2026)\")\n",
        "    years = list(range(2016, 2027))\n",
        "    values = []\n",
        "\n",
        "    for y in years:\n",
        "        try:\n",
        "            img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\n",
        "                .filterDate(f\"{y}-01-01\", f\"{y}-12-31\") \\\n",
        "                .filterBounds(region) \\\n",
        "                .select(\"Percent_Tree_Cover\") \\\n",
        "                .mean()\n",
        "\n",
        "            val_dict = img.reduceRegion(ee.Reducer.mean(), region, 250).getInfo()\n",
        "            tree_val = val_dict.get(\"Percent_Tree_Cover\", 0)\n",
        "            values.append(tree_val)\n",
        "        except Exception as e:\n",
        "            st.warning(f\"No data for year {y} or error occurred: {e}\")\n",
        "            values.append(0)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.plot(years, values, marker='o', linestyle='-')\n",
        "    ax.set_xlabel(\"Year\")\n",
        "    ax.set_ylabel(\"Tree Cover (%)\")\n",
        "    ax.set_title(\"Average Tree Cover Over Time\")\n",
        "    ax.grid(True)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "\n",
        "# ------------------ Page 4 ------------------\n",
        "if page == \"4Ô∏è‚É£ Environmental Statistics\":\n",
        "    st.header(\"üìä Environmental Stats (2015‚Äì2023)\")\n",
        "    param_bands = {\n",
        "        \"NDVI\": (\"MODIS/061/MOD13Q1\", \"NDVI\", 250, 0.0001),\n",
        "        \"EVI\": (\"MODIS/061/MOD13Q1\", \"EVI\", 250, 0.0001),\n",
        "        \"Precipitation\": (\"UCSB-CHG/CHIRPS/DAILY\", \"precipitation\", 5000, 1),\n",
        "        \"LST (¬∞C)\": (\"MODIS/061/MOD11A1\", \"LST_Day_1km\", 1000, 0.02)\n",
        "    }\n",
        "\n",
        "    start_year = 2015\n",
        "    end_year = 2023\n",
        "    data = {k: [] for k in param_bands}\n",
        "    labels = []\n",
        "\n",
        "    for y in range(start_year, end_year + 1):\n",
        "        start = f\"{y}-01-01\"\n",
        "        end = f\"{y}-12-31\"\n",
        "        labels.append(str(y))\n",
        "        for name, (ic, band, scale, factor) in param_bands.items():\n",
        "            coll = ee.ImageCollection(ic).filterDate(start, end).filterBounds(region)\n",
        "            img = coll.select(band).mean()\n",
        "            if name == \"LST (¬∞C)\":\n",
        "                img = img.multiply(factor).subtract(273.15)\n",
        "            elif factor != 1:\n",
        "                img = img.multiply(factor)\n",
        "            val = img.reduceRegion(ee.Reducer.mean(), region, scale).get(band).getInfo()\n",
        "            data[name].append(val if val is not None else 0)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    for name, series in data.items():\n",
        "        ax.plot(labels, series, marker='o', label=name)\n",
        "    ax.set_xlabel(\"Year\")\n",
        "    ax.set_title(\"Environmental Parameter Trends\")\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "SixKm6CQev6i"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"app6.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(code6)"
      ],
      "metadata": {
        "id": "y9JOCnDDfJJC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ImFTZF4fNNb",
        "outputId": "c8de22f0-0b79-4cfb-ebd4-e453b21fd45a"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.237.115.225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app6.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrD16_6PfRXw",
        "outputId": "897e596e-c5f3-4dc0-a7b4-624b5fbc276e"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.115.225:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0Kyour url is: https://twenty-states-relate.loca.lt\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/content/app6.py:165: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lat = selected_gdf.geometry.centroid.y.mean()\n",
            "/content/app6.py:166: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lon = selected_gdf.geometry.centroid.x.mean()\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/content/app6.py:165: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lat = selected_gdf.geometry.centroid.y.mean()\n",
            "/content/app6.py:166: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lon = selected_gdf.geometry.centroid.x.mean()\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/content/app6.py:165: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lat = selected_gdf.geometry.centroid.y.mean()\n",
            "/content/app6.py:166: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lon = selected_gdf.geometry.centroid.x.mean()\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/content/app6.py:165: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lat = selected_gdf.geometry.centroid.y.mean()\n",
            "/content/app6.py:166: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lon = selected_gdf.geometry.centroid.x.mean()\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code7 = '''\n",
        "import streamlit as st\n",
        "import folium\n",
        "from streamlit_folium import st_folium\n",
        "from folium.plugins import Draw\n",
        "import geopandas as gpd\n",
        "import datetime\n",
        "import numpy as np\n",
        "import joblib\n",
        "import ee\n",
        "from shapely.geometry import shape\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize EE\n",
        "ee.Initialize(project='ringed-trail-454308-d2')\n",
        "\n",
        "# Load model and scaler\n",
        "model = joblib.load(\"this_ensemble_model.pkl\")\n",
        "scaler = joblib.load(\"this_scaler.pkl\")\n",
        "\n",
        "# Load grid\n",
        "@st.cache_data\n",
        "def load_grid():\n",
        "    return gpd.read_file(\"Maharashtra_5x5km_Grid.geojson\")\n",
        "\n",
        "gdf = load_grid()\n",
        "\n",
        "# Streamlit setup\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"üå≥ Deforestation Analysis Tool\")\n",
        "\n",
        "# Navigation menu\n",
        "page = st.sidebar.radio(\"üìÇ Navigation\", [\n",
        "    \"üåç Region Selection\",\n",
        "    \"1Ô∏è‚É£ Visualize Environmental Layers\",\n",
        "    \"2Ô∏è‚É£ Predict Forest Cover\",\n",
        "    \"3Ô∏è‚É£ Timeline of Tree Cover\",\n",
        "    \"4Ô∏è‚É£ Environmental Statistics\"\n",
        "])\n",
        "\n",
        "# Page 0: Region Selection\n",
        "if page == \"üåç Region Selection\":\n",
        "    st.header(\"‚úèÔ∏è Draw a Region to Analyze\")\n",
        "    m = folium.Map(location=[19.5, 74], zoom_start=7.5)\n",
        "    Draw(export=True).add_to(m)\n",
        "    map_data = st_folium(m, height=600, width=900)\n",
        "\n",
        "    if map_data.get(\"last_active_drawing\"):\n",
        "        st.session_state[\"last_active_drawing\"] = map_data[\"last_active_drawing\"]\n",
        "        st.success(\"‚úÖ Region Selected! Now switch pages from the left sidebar.\")\n",
        "\n",
        "    st.stop()\n",
        "\n",
        "# Reset\n",
        "if st.sidebar.button(\"üîÑ Reset Region\"):\n",
        "    st.session_state.pop(\"last_active_drawing\", None)\n",
        "    st.rerun()\n",
        "\n",
        "if \"last_active_drawing\" not in st.session_state:\n",
        "    st.warning(\"‚ö†Ô∏è Please go to 'Region Selection' and draw a region first.\")\n",
        "    st.stop()\n",
        "\n",
        "# Selected region\n",
        "drawn_shape = shape(st.session_state[\"last_active_drawing\"][\"geometry\"])\n",
        "selected_gdf = gdf[gdf.intersects(drawn_shape)].copy()\n",
        "region = ee.Geometry.Polygon([list(drawn_shape.exterior.coords)])\n",
        "\n",
        "if selected_gdf.empty:\n",
        "    st.warning(\"‚ö†Ô∏è No grid found in selected region.\")\n",
        "    st.stop()\n",
        "\n",
        "# ------------------ Helper: Compute EE features ------------------\n",
        "def compute_features(lon, lat, start_date, end_date):\n",
        "    point = ee.Geometry.Point([lon, lat])\n",
        "    try:\n",
        "        mod13 = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(point) \\\n",
        "            .select([\"NDVI\", \"EVI\"]).mean()\n",
        "\n",
        "        evi = mod13.select(\"EVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"EVI\").getInfo()\n",
        "        ndvi = mod13.select(\"NDVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"NDVI\").getInfo()\n",
        "\n",
        "        def add_ndmi(img):\n",
        "            return img.addBands(img.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).rename(\"NDMI\"))\n",
        "\n",
        "        ndmi_img = ee.ImageCollection(\"MODIS/061/MOD09GA\") \\\n",
        "            .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\n",
        "            .map(add_ndmi).select(\"NDMI\").mean()\n",
        "        ndmi = ndmi_img.reduceRegion(ee.Reducer.mean(), point, 500).get(\"NDMI\").getInfo()\n",
        "\n",
        "        precip = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(point).sum().select(\"precipitation\") \\\n",
        "            .reduceRegion(ee.Reducer.mean(), point, 5000).get(\"precipitation\").getInfo()\n",
        "\n",
        "        lst_img = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(point).select(\"LST_Day_1km\").mean()\n",
        "        lst = lst_img.multiply(0.02).subtract(273.15).reduceRegion(ee.Reducer.mean(), point, 1000).get(\"LST_Day_1km\").getInfo()\n",
        "\n",
        "        tree_img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\n",
        "            .filterBounds(point).select(\"Percent_Tree_Cover\").mean()\n",
        "        treecover = tree_img.reduceRegion(ee.Reducer.mean(), point, 250).get(\"Percent_Tree_Cover\").getInfo()\n",
        "\n",
        "        return [evi, ndvi, ndmi, lst, precip, treecover]\n",
        "    except:\n",
        "        return [None]*6\n",
        "\n",
        "# ------------------ Page 1 ------------------\n",
        "if page == \"1Ô∏è‚É£ Visualize Environment Layers\":\n",
        "    st.header(\"üåç Environmental Parameters in Selected Region\")\n",
        "    opacity = st.slider(\"üñåÔ∏è Layer Opacity\", 0.1, 1.0, 0.6)\n",
        "\n",
        "    vis_options = {\n",
        "        \"LST (¬∞C)\": {\n",
        "            \"collection\": \"MODIS/061/MOD11A1\",\n",
        "            \"band\": \"LST_Day_1km\",\n",
        "            \"scale\": 1000,\n",
        "            \"palette\": ['#f7fcf0', '#ccece6', '#66c2a4', '#238b45', '#005824'],\n",
        "            \"transform\": lambda img: img.multiply(0.02).subtract(273.15),\n",
        "            \"vmin\": 15, \"vmax\": 45\n",
        "        },\n",
        "        \"Precipitation (mm)\": {\n",
        "            \"collection\": \"UCSB-CHG/CHIRPS/DAILY\",\n",
        "            \"band\": \"precipitation\",\n",
        "            \"scale\": 5000,\n",
        "            \"palette\": ['#f7fbff', '#deebf7', '#9ecae1', '#3182bd', '#08519c'],\n",
        "            \"transform\": lambda img: img,\n",
        "            \"vmin\": 0, \"vmax\": 200\n",
        "        },\n",
        "        \"Tree Cover (%)\": {\n",
        "            \"collection\": \"MODIS/061/MOD44B\",\n",
        "            \"band\": \"Percent_Tree_Cover\",\n",
        "            \"scale\": 250,\n",
        "            \"palette\": ['#f7fcfd', '#e0ecf4', '#bfd3e6', '#9ebcda', '#8c96c6', '#8856a7', '#810f7c'],\n",
        "            \"transform\": lambda img: img,\n",
        "            \"vmin\": 0, \"vmax\": 100\n",
        "        },\n",
        "        \"EVI\": {\n",
        "            \"collection\": \"MODIS/061/MOD13Q1\",\n",
        "            \"band\": \"EVI\",\n",
        "            \"scale\": 250,\n",
        "            \"palette\": ['#ffffcc', '#c2e699', '#78c679', '#31a354', '#006837'],\n",
        "            \"transform\": lambda img: img.multiply(0.0001),\n",
        "            \"vmin\": 0, \"vmax\": 0.8\n",
        "        },\n",
        "        \"NDMI\": {\n",
        "            \"collection\": \"MODIS/061/MOD09GA\",\n",
        "            \"band\": \"NDMI\",\n",
        "            \"scale\": 500,\n",
        "            \"palette\": ['#ffffe5', '#f7fcb9', '#addd8e', '#31a354', '#006837'],\n",
        "            \"transform\": lambda img: img.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).rename(\"NDMI\"),\n",
        "            \"vmin\": -0.2, \"vmax\": 0.6\n",
        "        }\n",
        "    }\n",
        "\n",
        "    selected_layer = st.selectbox(\"üåê Choose a parameter to visualize\", list(vis_options.keys()))\n",
        "    vis_info = vis_options[selected_layer]\n",
        "\n",
        "    col = ee.ImageCollection(vis_info[\"collection\"]) \\\n",
        "        .filterDate(str(datetime.date.today() - datetime.timedelta(days=30)), str(datetime.date.today())) \\\n",
        "        .select(vis_info[\"band\"])\n",
        "\n",
        "    img = col.mean()\n",
        "    img = vis_info[\"transform\"](img)\n",
        "    img = img.clip(region)  # ‚úÖ Clip to selected region only\n",
        "\n",
        "    vis_params = {\n",
        "        \"min\": vis_info[\"vmin\"],\n",
        "        \"max\": vis_info[\"vmax\"],\n",
        "        \"palette\": vis_info[\"palette\"]\n",
        "    }\n",
        "\n",
        "    tile_url = img.getMapId(vis_params)[\"tile_fetcher\"].url_format\n",
        "    m = folium.Map(location=[region.centroid().coordinates().getInfo()[1],\n",
        "                             region.centroid().coordinates().getInfo()[0]], zoom_start=8)\n",
        "\n",
        "    folium.raster_layers.TileLayer(\n",
        "        tiles=tile_url,\n",
        "        name=selected_layer,\n",
        "        opacity=opacity,\n",
        "        attr=\"Map data ¬© Google Earth Engine\"\n",
        "    ).add_to(m)\n",
        "\n",
        "    folium.GeoJson(region.getInfo(), name=\"Selected Region\",\n",
        "                   style_function=lambda x: {\n",
        "                       \"fillOpacity\": 0,\n",
        "                       \"color\": \"black\",\n",
        "                       \"weight\": 2\n",
        "                   }).add_to(m)\n",
        "\n",
        "    st_folium(m, height=600, width=900)\n",
        "\n",
        "# ------------------ Page 2 ------------------\n",
        "if page == \"2Ô∏è‚É£ Predict Forest Cover\":\n",
        "    st.header(\"üß† Forest Cover Prediction\")\n",
        "    st.info(f\"Selected {len(selected_gdf)} grid cells for prediction.\")\n",
        "\n",
        "    end_date = datetime.date.today()\n",
        "    start_date = end_date - datetime.timedelta(days=30)\n",
        "\n",
        "    features = []\n",
        "    for _, row in selected_gdf.iterrows():\n",
        "        lon, lat = row.geometry.centroid.x, row.geometry.centroid.y\n",
        "        feats = compute_features(lon, lat, start_date, end_date)\n",
        "        features.append((row[\"geometry\"], feats))\n",
        "\n",
        "    X = [[f[1][i] for i in [0, 2, 3, 4, 5]] if None not in f[1] else [0]*5 for f in features]  # Drop NDVI\n",
        "    param_data = [{\n",
        "        \"EVI\": round(f[1][0], 4) if f[1][0] is not None else \"N/A\",\n",
        "        \"NDMI\": round(f[1][2], 4) if f[1][2] is not None else \"N/A\",\n",
        "        \"LST Anomaly\": round(f[1][3] - 30, 2) if f[1][3] is not None else \"N/A\",\n",
        "        \"Precip Anomaly\": round(f[1][4] - 50, 2) if f[1][4] is not None else \"N/A\",\n",
        "        \"Tree Cover\": round(f[1][5], 1) if f[1][5] is not None else \"N/A\"\n",
        "    } for f in features]\n",
        "\n",
        "    X_scaled = scaler.transform(np.array(X))\n",
        "    y_pred = model.predict(X_scaled)\n",
        "\n",
        "    center_lat = selected_gdf.geometry.centroid.y.mean()\n",
        "    center_lon = selected_gdf.geometry.centroid.x.mean()\n",
        "    opacity = st.slider(\"üñåÔ∏è Prediction Fill Opacity\", 0.1, 1.0, 0.6)\n",
        "\n",
        "    result_map = folium.Map(location=[center_lat, center_lon], zoom_start=9.5)\n",
        "\n",
        "    for idx, (geom, pred) in enumerate(zip([f[0] for f in features], y_pred)):\n",
        "        tooltip_text = \"<br>\".join([f\"{k}: {v}\" for k, v in param_data[idx].items()])\n",
        "        tooltip_text += \"<br><b>Prediction</b>: \" + (\"üå≥ Forest\" if pred == 0 else \"ü™µ Deforested\")\n",
        "        fill = \"green\" if pred == 0 else \"red\"\n",
        "\n",
        "        folium.GeoJson(\n",
        "            geom,\n",
        "            tooltip=tooltip_text,\n",
        "            style_function=lambda x, fill_color=fill: {\n",
        "                \"fillColor\": fill_color,\n",
        "                \"color\": \"black\",\n",
        "                \"weight\": 0.5,\n",
        "                \"fillOpacity\": opacity\n",
        "            }\n",
        "        ).add_to(result_map)\n",
        "\n",
        "    st.subheader(\"üó∫Ô∏è Predicted Forest Cover\")\n",
        "    st_folium(result_map, height=600, width=900)\n",
        "\n",
        "\n",
        "# ------------------ Page 3 ------------------\n",
        "if page == \"3Ô∏è‚É£ Timeline of Tree Cover\":\n",
        "    st.header(\"üìΩÔ∏è Animated Timeline of EVI (2016‚Äì2025)\")\n",
        "    years = list(range(2016, 2026))\n",
        "\n",
        "    image_list = []\n",
        "\n",
        "    for y in years:\n",
        "        # Create EVI mean image for the year\n",
        "        img = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "            .filterDate(f\"{y}-01-01\", f\"{y}-12-31\") \\\n",
        "            .filterBounds(region) \\\n",
        "            .select(\"EVI\") \\\n",
        "            .mean() \\\n",
        "            .multiply(0.0001) \\\n",
        "            .clip(region)\n",
        "\n",
        "        # Visualize it for thumbnail export\n",
        "        vis = img.visualize(**{\n",
        "            \"min\": 0,\n",
        "            \"max\": 0.8,\n",
        "            \"palette\": ['#ffffcc', '#c2e699', '#78c679', '#31a354', '#006837']\n",
        "        }).set({'label': str(y)})\n",
        "\n",
        "        image_list.append(vis)\n",
        "\n",
        "    # Convert to server-side ImageCollection\n",
        "    gif_collection = ee.ImageCollection.fromImages(image_list)\n",
        "\n",
        "    # Define video thumbnail arguments\n",
        "    video_args = {\n",
        "        'dimensions': 600,\n",
        "        'region': region.bounds(),\n",
        "        'framesPerSecond': 1,\n",
        "        'format': 'gif'\n",
        "    }\n",
        "\n",
        "    # Get thumbnail (animated gif) URL\n",
        "    url = gif_collection.getVideoThumbURL(video_args)\n",
        "\n",
        "    st.markdown(\"#### üåø EVI Timeline Over Selected Region\")\n",
        "    st.image(url, caption=\"EVI Animation (2016‚Äì2025)\")\n",
        "\n",
        "\n",
        "# ------------------ Page 4 ------------------\n",
        "if page == \"4Ô∏è‚É£ Environmental Statistics\":\n",
        "    st.header(\"üìä Environmental Stats (2015‚Äì2023)\")\n",
        "    param_bands = {\n",
        "        \"NDVI\": (\"MODIS/061/MOD13Q1\", \"NDVI\", 250, 0.0001),\n",
        "        \"EVI\": (\"MODIS/061/MOD13Q1\", \"EVI\", 250, 0.0001),\n",
        "        \"Precipitation\": (\"UCSB-CHG/CHIRPS/DAILY\", \"precipitation\", 5000, 1),\n",
        "        \"LST (¬∞C)\": (\"MODIS/061/MOD11A1\", \"LST_Day_1km\", 1000, 0.02)\n",
        "    }\n",
        "\n",
        "    start_year = 2015\n",
        "    end_year = 2023\n",
        "    data = {k: [] for k in param_bands}\n",
        "    labels = []\n",
        "\n",
        "    for y in range(start_year, end_year + 1):\n",
        "        start = f\"{y}-01-01\"\n",
        "        end = f\"{y}-12-31\"\n",
        "        labels.append(str(y))\n",
        "        for name, (ic, band, scale, factor) in param_bands.items():\n",
        "            coll = ee.ImageCollection(ic).filterDate(start, end).filterBounds(region)\n",
        "            img = coll.select(band).mean()\n",
        "            if name == \"LST (¬∞C)\":\n",
        "                img = img.multiply(factor).subtract(273.15)\n",
        "            elif factor != 1:\n",
        "                img = img.multiply(factor)\n",
        "            val = img.reduceRegion(ee.Reducer.mean(), region, scale).get(band).getInfo()\n",
        "            data[name].append(val if val is not None else 0)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    for name, series in data.items():\n",
        "        ax.plot(labels, series, marker='o', label=name)\n",
        "    ax.set_xlabel(\"Year\")\n",
        "    ax.set_title(\"Environmental Parameter Trends\")\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "zX0MYmdbfS1h"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"app7.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(code7)"
      ],
      "metadata": {
        "id": "89rOxeCYnVVX"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzqXnSI7neuA",
        "outputId": "88b49934-7cfe-41f8-dd58-a14077f60676"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.237.115.225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app7.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQqf-3uenfzw",
        "outputId": "836435af-d44f-4cc7-8980-e6ab65d6fbf7"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.115.225:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0Kyour url is: https://moody-seals-rule.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code8 = '''\n",
        "import streamlit as st\n",
        "import folium\n",
        "from streamlit_folium import st_folium\n",
        "from folium.plugins import Draw\n",
        "import geopandas as gpd\n",
        "import datetime\n",
        "import numpy as np\n",
        "import joblib\n",
        "import ee\n",
        "from shapely.geometry import shape\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize EE\n",
        "ee.Initialize(project='ringed-trail-454308-d2')\n",
        "\n",
        "# Load model and scaler\n",
        "model = joblib.load(\"this_ensemble_model.pkl\")\n",
        "scaler = joblib.load(\"this_scaler.pkl\")\n",
        "\n",
        "# Load grid\n",
        "@st.cache_data\n",
        "def load_grid():\n",
        "    return gpd.read_file(\"Maharashtra_5x5km_Grid.geojson\")\n",
        "\n",
        "gdf = load_grid()\n",
        "\n",
        "# Streamlit setup\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"üå≥ Deforestation Analysis Tool\")\n",
        "\n",
        "# Navigation menu\n",
        "page = st.sidebar.radio(\"üìÇ Navigation\", [\n",
        "    \"üåç Region Selection\",\n",
        "    \"1Ô∏è‚É£ Visualize Environmental Layers\",\n",
        "    \"2Ô∏è‚É£ Predict Forest Cover\",\n",
        "    \"3Ô∏è‚É£ Timeline of Tree Cover\",\n",
        "    \"4Ô∏è‚É£ Environmental Statistics\"\n",
        "])\n",
        "\n",
        "# Page 0: Region Selection\n",
        "if page == \"üåç Region Selection\":\n",
        "    st.header(\"‚úèÔ∏è Draw a Region to Analyze\")\n",
        "    m = folium.Map(location=[19.5, 74], zoom_start=7.5)\n",
        "    Draw(export=True).add_to(m)\n",
        "    map_data = st_folium(m, height=600, width=900)\n",
        "\n",
        "    if map_data.get(\"last_active_drawing\"):\n",
        "        st.session_state[\"last_active_drawing\"] = map_data[\"last_active_drawing\"]\n",
        "        st.success(\"‚úÖ Region Selected! Now switch pages from the left sidebar.\")\n",
        "\n",
        "    st.stop()\n",
        "\n",
        "# Reset\n",
        "if st.sidebar.button(\"üîÑ Reset Region\"):\n",
        "    st.session_state.pop(\"last_active_drawing\", None)\n",
        "    st.rerun()\n",
        "\n",
        "if \"last_active_drawing\" not in st.session_state:\n",
        "    st.warning(\"‚ö†Ô∏è Please go to 'Region Selection' and draw a region first.\")\n",
        "    st.stop()\n",
        "\n",
        "# Selected region\n",
        "drawn_shape = shape(st.session_state[\"last_active_drawing\"][\"geometry\"])\n",
        "selected_gdf = gdf[gdf.intersects(drawn_shape)].copy()\n",
        "region = ee.Geometry.Polygon([list(drawn_shape.exterior.coords)])\n",
        "\n",
        "if selected_gdf.empty:\n",
        "    st.warning(\"‚ö†Ô∏è No grid found in selected region.\")\n",
        "    st.stop()\n",
        "\n",
        "# ------------------ Helper: Compute EE features ------------------\n",
        "def compute_features(lon, lat, start_date, end_date):\n",
        "    point = ee.Geometry.Point([lon, lat])\n",
        "    try:\n",
        "        mod13 = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(point) \\\n",
        "            .select([\"NDVI\", \"EVI\"]).mean()\n",
        "\n",
        "        evi = mod13.select(\"EVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"EVI\").getInfo()\n",
        "        ndvi = mod13.select(\"NDVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"NDVI\").getInfo()\n",
        "\n",
        "        def add_ndmi(img):\n",
        "            return img.addBands(img.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).rename(\"NDMI\"))\n",
        "\n",
        "        ndmi_img = ee.ImageCollection(\"MODIS/061/MOD09GA\") \\\n",
        "            .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\n",
        "            .map(add_ndmi).select(\"NDMI\").mean()\n",
        "        ndmi = ndmi_img.reduceRegion(ee.Reducer.mean(), point, 500).get(\"NDMI\").getInfo()\n",
        "\n",
        "        precip = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(point).sum().select(\"precipitation\") \\\n",
        "            .reduceRegion(ee.Reducer.mean(), point, 5000).get(\"precipitation\").getInfo()\n",
        "\n",
        "        lst_img = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(point).select(\"LST_Day_1km\").mean()\n",
        "        lst = lst_img.multiply(0.02).subtract(273.15).reduceRegion(ee.Reducer.mean(), point, 1000).get(\"LST_Day_1km\").getInfo()\n",
        "\n",
        "        tree_img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\n",
        "            .filterBounds(point).select(\"Percent_Tree_Cover\").mean()\n",
        "        treecover = tree_img.reduceRegion(ee.Reducer.mean(), point, 250).get(\"Percent_Tree_Cover\").getInfo()\n",
        "\n",
        "        return [evi, ndvi, ndmi, lst, precip, treecover]\n",
        "    except:\n",
        "        return [None]*6\n",
        "\n",
        "# ------------------ Page 1 ------------------\n",
        "if page == \"1Ô∏è‚É£ Visualize Environment Layers\":\n",
        "    st.header(\"üåç Environmental Parameters in Selected Region\")\n",
        "    opacity = st.slider(\"üñåÔ∏è Layer Opacity\", 0.1, 1.0, 0.6)\n",
        "\n",
        "    vis_options = {\n",
        "        \"LST (¬∞C)\": {\n",
        "            \"collection\": \"MODIS/061/MOD11A1\",\n",
        "            \"band\": \"LST_Day_1km\",\n",
        "            \"scale\": 1000,\n",
        "            \"palette\": ['#f7fcf0', '#ccece6', '#66c2a4', '#238b45', '#005824'],\n",
        "            \"transform\": lambda img: img.multiply(0.02).subtract(273.15),\n",
        "            \"vmin\": 15, \"vmax\": 45\n",
        "        },\n",
        "        \"Precipitation (mm)\": {\n",
        "            \"collection\": \"UCSB-CHG/CHIRPS/DAILY\",\n",
        "            \"band\": \"precipitation\",\n",
        "            \"scale\": 5000,\n",
        "            \"palette\": ['#f7fbff', '#deebf7', '#9ecae1', '#3182bd', '#08519c'],\n",
        "            \"transform\": lambda img: img,\n",
        "            \"vmin\": 0, \"vmax\": 200\n",
        "        },\n",
        "        \"Tree Cover (%)\": {\n",
        "            \"collection\": \"MODIS/061/MOD44B\",\n",
        "            \"band\": \"Percent_Tree_Cover\",\n",
        "            \"scale\": 250,\n",
        "            \"palette\": ['#f7fcfd', '#e0ecf4', '#bfd3e6', '#9ebcda', '#8c96c6', '#8856a7', '#810f7c'],\n",
        "            \"transform\": lambda img: img,\n",
        "            \"vmin\": 0, \"vmax\": 100\n",
        "        },\n",
        "        \"EVI\": {\n",
        "            \"collection\": \"MODIS/061/MOD13Q1\",\n",
        "            \"band\": \"EVI\",\n",
        "            \"scale\": 250,\n",
        "            \"palette\": ['#ffffcc', '#c2e699', '#78c679', '#31a354', '#006837'],\n",
        "            \"transform\": lambda img: img.multiply(0.0001),\n",
        "            \"vmin\": 0, \"vmax\": 0.8\n",
        "        },\n",
        "        \"NDMI\": {\n",
        "            \"collection\": \"MODIS/061/MOD09GA\",\n",
        "            \"band\": \"NDMI\",\n",
        "            \"scale\": 500,\n",
        "            \"palette\": ['#ffffe5', '#f7fcb9', '#addd8e', '#31a354', '#006837'],\n",
        "            \"transform\": lambda img: img.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).rename(\"NDMI\"),\n",
        "            \"vmin\": -0.2, \"vmax\": 0.6\n",
        "        }\n",
        "    }\n",
        "\n",
        "    selected_layer = st.selectbox(\"üåê Choose a parameter to visualize\", list(vis_options.keys()))\n",
        "    vis_info = vis_options[selected_layer]\n",
        "\n",
        "    col = ee.ImageCollection(vis_info[\"collection\"]) \\\n",
        "        .filterDate(str(datetime.date.today() - datetime.timedelta(days=30)), str(datetime.date.today())) \\\n",
        "        .select(vis_info[\"band\"])\n",
        "\n",
        "    img = col.mean()\n",
        "    img = vis_info[\"transform\"](img)\n",
        "    img = img.clip(region)  # ‚úÖ Clip to selected region only\n",
        "\n",
        "    vis_params = {\n",
        "        \"min\": vis_info[\"vmin\"],\n",
        "        \"max\": vis_info[\"vmax\"],\n",
        "        \"palette\": vis_info[\"palette\"]\n",
        "    }\n",
        "\n",
        "    tile_url = img.getMapId(vis_params)[\"tile_fetcher\"].url_format\n",
        "    m = folium.Map(location=[region.centroid().coordinates().getInfo()[1],\n",
        "                             region.centroid().coordinates().getInfo()[0]], zoom_start=8)\n",
        "\n",
        "    folium.raster_layers.TileLayer(\n",
        "        tiles=tile_url,\n",
        "        name=selected_layer,\n",
        "        opacity=opacity,\n",
        "        attr=\"Map data ¬© Google Earth Engine\"\n",
        "    ).add_to(m)\n",
        "\n",
        "    folium.GeoJson(region.getInfo(), name=\"Selected Region\",\n",
        "                   style_function=lambda x: {\n",
        "                       \"fillOpacity\": 0,\n",
        "                       \"color\": \"black\",\n",
        "                       \"weight\": 2\n",
        "                   }).add_to(m)\n",
        "\n",
        "    st_folium(m, height=600, width=900)\n",
        "\n",
        "# ------------------ Page 2 ------------------\n",
        "if page == \"2Ô∏è‚É£ Predict Forest Cover\":\n",
        "    st.header(\"üß† Forest Cover Prediction\")\n",
        "    st.info(f\"Selected {len(selected_gdf)} grid cells for prediction.\")\n",
        "\n",
        "    end_date = datetime.date.today()\n",
        "    start_date = end_date - datetime.timedelta(days=30)\n",
        "\n",
        "    features = []\n",
        "    for _, row in selected_gdf.iterrows():\n",
        "        lon, lat = row.geometry.centroid.x, row.geometry.centroid.y\n",
        "        feats = compute_features(lon, lat, start_date, end_date)\n",
        "        features.append((row[\"geometry\"], feats))\n",
        "\n",
        "    X = [[f[1][i] for i in [0, 2, 3, 4, 5]] if None not in f[1] else [0]*5 for f in features]  # Drop NDVI\n",
        "    param_data = [{\n",
        "        \"EVI\": round(f[1][0], 4) if f[1][0] is not None else \"N/A\",\n",
        "        \"NDMI\": round(f[1][2], 4) if f[1][2] is not None else \"N/A\",\n",
        "        \"LST Anomaly\": round(f[1][3] - 30, 2) if f[1][3] is not None else \"N/A\",\n",
        "        \"Precip Anomaly\": round(f[1][4] - 50, 2) if f[1][4] is not None else \"N/A\",\n",
        "        \"Tree Cover\": round(f[1][5], 1) if f[1][5] is not None else \"N/A\"\n",
        "    } for f in features]\n",
        "\n",
        "    X_scaled = scaler.transform(np.array(X))\n",
        "    y_pred = model.predict(X_scaled)\n",
        "\n",
        "    center_lat = selected_gdf.geometry.centroid.y.mean()\n",
        "    center_lon = selected_gdf.geometry.centroid.x.mean()\n",
        "    opacity = st.slider(\"üñåÔ∏è Prediction Fill Opacity\", 0.1, 1.0, 0.6)\n",
        "\n",
        "    result_map = folium.Map(location=[center_lat, center_lon], zoom_start=9.5)\n",
        "\n",
        "    for idx, (geom, pred) in enumerate(zip([f[0] for f in features], y_pred)):\n",
        "        tooltip_text = \"<br>\".join([f\"{k}: {v}\" for k, v in param_data[idx].items()])\n",
        "        tooltip_text += \"<br><b>Prediction</b>: \" + (\"üå≥ Forest\" if pred == 0 else \"ü™µ Deforested\")\n",
        "        fill = \"green\" if pred == 0 else \"red\"\n",
        "\n",
        "        folium.GeoJson(\n",
        "            geom,\n",
        "            tooltip=tooltip_text,\n",
        "            style_function=lambda x, fill_color=fill: {\n",
        "                \"fillColor\": fill_color,\n",
        "                \"color\": \"black\",\n",
        "                \"weight\": 0.5,\n",
        "                \"fillOpacity\": opacity\n",
        "            }\n",
        "        ).add_to(result_map)\n",
        "\n",
        "    st.subheader(\"üó∫Ô∏è Predicted Forest Cover\")\n",
        "    st_folium(result_map, height=600, width=900)\n",
        "\n",
        "\n",
        "# ------------------ Page 3 ------------------\n",
        "if page == \"3Ô∏è‚É£ Timeline of Tree Cover\":\n",
        "    st.header(\"üìΩÔ∏è Animated Timeline of EVI (2016‚Äì2025)\")\n",
        "    years = list(range(2016, 2026))\n",
        "\n",
        "    # --------- Helper function to create EVI image ---------\n",
        "    def create_evi_image(year):\n",
        "        evi = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "            .filterDate(f\"{year}-01-01\", f\"{year}-12-31\") \\\n",
        "            .filterBounds(region) \\\n",
        "            .select(\"EVI\") \\\n",
        "            .mean() \\\n",
        "            .multiply(0.0001) \\\n",
        "            .clip(region)\n",
        "\n",
        "        evi_viz = evi.visualize(**{\n",
        "            \"min\": 0,\n",
        "            \"max\": 0.8,\n",
        "            \"palette\": ['#ffffcc', '#c2e699', '#78c679', '#31a354', '#006837']\n",
        "        })\n",
        "\n",
        "        return evi_viz.set({'label': str(year)})\n",
        "\n",
        "    # Generate image list for GIF\n",
        "    image_list = [create_evi_image(y) for y in years]\n",
        "    gif_collection = ee.ImageCollection(image_list)\n",
        "\n",
        "    video_args = {\n",
        "        'dimensions': 400,  # Smaller gif width\n",
        "        'region': region.bounds(),\n",
        "        'framesPerSecond': 1,\n",
        "        'format': 'gif'\n",
        "    }\n",
        "\n",
        "    gif_url = gif_collection.getVideoThumbURL(video_args)\n",
        "\n",
        "    st.subheader(\"üéûÔ∏è EVI Animation Over Selected Region\")\n",
        "    st.image(gif_url, caption=\"üåø Animated EVI Change (2016‚Äì2025)\", width=400)\n",
        "\n",
        "    # --------- Strip of yearly EVI thumbnails ----------\n",
        "    st.markdown(\"### üìä Yearly EVI Snapshots\")\n",
        "\n",
        "    thumb_images = []\n",
        "    for year in years:\n",
        "        evi = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "            .filterDate(f\"{year}-01-01\", f\"{year}-12-31\") \\\n",
        "            .filterBounds(region) \\\n",
        "            .select(\"EVI\") \\\n",
        "            .mean() \\\n",
        "            .multiply(0.0001) \\\n",
        "            .clip(region)\n",
        "\n",
        "        vis = {\n",
        "            \"min\": 0,\n",
        "            \"max\": 0.8,\n",
        "            \"palette\": ['#ffffcc', '#c2e699', '#78c679', '#31a354', '#006837']\n",
        "        }\n",
        "\n",
        "        url = evi.visualize(**vis).getThumbURL({\n",
        "            \"region\": region.bounds().getInfo(),\n",
        "            \"dimensions\": 150,\n",
        "            \"format\": \"png\"\n",
        "        })\n",
        "\n",
        "        thumb_images.append((year, url))\n",
        "\n",
        "    # Display as a strip\n",
        "    cols = st.columns(len(thumb_images))\n",
        "    for i, (yr, url) in enumerate(thumb_images):\n",
        "        with cols[i]:\n",
        "            st.image(url, caption=str(yr), use_container_width=True)\n",
        "\n",
        "\n",
        "# ------------------ Page 4 ------------------\n",
        "if page == \"4Ô∏è‚É£ Environmental Statistics\":\n",
        "    st.header(\"üìä Environmental Stats (2015‚Äì2023)\")\n",
        "    param_bands = {\n",
        "        \"NDVI\": (\"MODIS/061/MOD13Q1\", \"NDVI\", 250, 0.0001),\n",
        "        \"EVI\": (\"MODIS/061/MOD13Q1\", \"EVI\", 250, 0.0001),\n",
        "        \"Precipitation\": (\"UCSB-CHG/CHIRPS/DAILY\", \"precipitation\", 5000, 1),\n",
        "        \"LST (¬∞C)\": (\"MODIS/061/MOD11A1\", \"LST_Day_1km\", 1000, 0.02)\n",
        "    }\n",
        "\n",
        "    start_year = 2015\n",
        "    end_year = 2023\n",
        "    data = {k: [] for k in param_bands}\n",
        "    labels = []\n",
        "\n",
        "    for y in range(start_year, end_year + 1):\n",
        "        start = f\"{y}-01-01\"\n",
        "        end = f\"{y}-12-31\"\n",
        "        labels.append(str(y))\n",
        "        for name, (ic, band, scale, factor) in param_bands.items():\n",
        "            coll = ee.ImageCollection(ic).filterDate(start, end).filterBounds(region)\n",
        "            img = coll.select(band).mean()\n",
        "            if name == \"LST (¬∞C)\":\n",
        "                img = img.multiply(factor).subtract(273.15)\n",
        "            elif factor != 1:\n",
        "                img = img.multiply(factor)\n",
        "            val = img.reduceRegion(ee.Reducer.mean(), region, scale).get(band).getInfo()\n",
        "            data[name].append(val if val is not None else 0)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    for name, series in data.items():\n",
        "        ax.plot(labels, series, marker='o', label=name)\n",
        "    ax.set_xlabel(\"Year\")\n",
        "    ax.set_title(\"Environmental Parameter Trends\")\n",
        "    ax.legend()\n",
        "    ax.grid(True)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "cObOUFRznh-2"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"app8.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(code8)"
      ],
      "metadata": {
        "id": "x2XF__WmteLj"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlDdrxautj1I",
        "outputId": "9bf37ab4-16ed-48e7-9a82-7f0de63dd379"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.237.115.225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app8.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMAEe9TwtpJu",
        "outputId": "15f51289-7e53-46a5-b48a-4f456b1acec2"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.115.225:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0Kyour url is: https://hungry-keys-strive.loca.lt\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/content/app8.py:209: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lat = selected_gdf.geometry.centroid.y.mean()\n",
            "/content/app8.py:210: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lon = selected_gdf.geometry.centroid.x.mean()\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/content/app8.py:209: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lat = selected_gdf.geometry.centroid.y.mean()\n",
            "/content/app8.py:210: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lon = selected_gdf.geometry.centroid.x.mean()\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/content/app8.py:209: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lat = selected_gdf.geometry.centroid.y.mean()\n",
            "/content/app8.py:210: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
            "\n",
            "  center_lon = selected_gdf.geometry.centroid.x.mean()\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code9 = '''\n",
        "import streamlit as st\n",
        "import folium\n",
        "from streamlit_folium import st_folium\n",
        "from folium.plugins import Draw\n",
        "import geopandas as gpd\n",
        "import datetime\n",
        "import numpy as np\n",
        "import joblib\n",
        "import ee\n",
        "from shapely.geometry import shape\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "# Initialize EE\n",
        "ee.Initialize(project='ringed-trail-454308-d2')\n",
        "\n",
        "# Load model and scaler\n",
        "model = joblib.load(\"this_ensemble_model.pkl\")\n",
        "scaler = joblib.load(\"this_scaler.pkl\")\n",
        "\n",
        "# Load grid\n",
        "@st.cache_data\n",
        "def load_grid():\n",
        "    return gpd.read_file(\"Maharashtra_5x5km_Grid.geojson\")\n",
        "\n",
        "gdf = load_grid()\n",
        "\n",
        "# Streamlit setup\n",
        "st.set_page_config(layout=\"wide\")\n",
        "st.title(\"üå≥ Deforestation Analysis Tool\")\n",
        "\n",
        "# Navigation menu\n",
        "page = st.sidebar.radio(\"üìÇ Navigation\", [\n",
        "    \"Region Selection\",\n",
        "    \"Predict Forest Cover\",\n",
        "    \"Timeline of Tree Cover\",\n",
        "    \"Environmental Statistics\"\n",
        "])\n",
        "\n",
        "# Page 0: Region Selection\n",
        "if page == \"Region Selection\":\n",
        "    st.header(\":pencil2: Draw a Region to Analyze\")\n",
        "    m = folium.Map(location=[19.5, 74], zoom_start=7.5)\n",
        "    Draw(export=True).add_to(m)\n",
        "    map_data = st_folium(m, height=600, width=900)\n",
        "\n",
        "    if map_data.get(\"last_active_drawing\"):\n",
        "        st.session_state[\"last_active_drawing\"] = map_data[\"last_active_drawing\"]\n",
        "        st.success(\"‚úÖ Region Selected! Now switch pages from the left sidebar.\")\n",
        "\n",
        "    st.stop()\n",
        "\n",
        "# Reset button\n",
        "if st.sidebar.button(\"üîÑ Reset Region\"):\n",
        "    st.session_state.pop(\"last_active_drawing\", None)\n",
        "    st.rerun()\n",
        "\n",
        "if \"last_active_drawing\" not in st.session_state:\n",
        "    st.warning(\"‚ö†Ô∏è Please go to 'Region Selection' and draw a region first.\")\n",
        "    st.stop()\n",
        "\n",
        "# Selected region\n",
        "drawn_shape = shape(st.session_state[\"last_active_drawing\"][\"geometry\"])\n",
        "selected_gdf = gdf[gdf.intersects(drawn_shape)].copy()\n",
        "region = ee.Geometry.Polygon([list(drawn_shape.exterior.coords)])\n",
        "\n",
        "if selected_gdf.empty:\n",
        "    st.warning(\"‚ö†Ô∏è No grid found in selected region.\")\n",
        "    st.stop()\n",
        "\n",
        "# ------------------ Helper: Compute EE features ------------------\n",
        "def compute_features(lon, lat, start_date, end_date):\n",
        "    point = ee.Geometry.Point([lon, lat])\n",
        "    try:\n",
        "        mod13 = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(point) \\\n",
        "            .select([\"NDVI\", \"EVI\"]).mean()\n",
        "\n",
        "        evi = mod13.select(\"EVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"EVI\").getInfo()\n",
        "        ndvi = mod13.select(\"NDVI\").multiply(0.0001).reduceRegion(ee.Reducer.mean(), point, 250).get(\"NDVI\").getInfo()\n",
        "\n",
        "        def add_ndmi(img):\n",
        "            return img.addBands(img.normalizedDifference(['sur_refl_b02', 'sur_refl_b06']).rename(\"NDMI\"))\n",
        "\n",
        "        ndmi_img = ee.ImageCollection(\"MODIS/061/MOD09GA\") \\\n",
        "            .filterBounds(point).filterDate(str(start_date), str(end_date)) \\\n",
        "            .map(add_ndmi).select(\"NDMI\").mean()\n",
        "        ndmi = ndmi_img.reduceRegion(ee.Reducer.mean(), point, 500).get(\"NDMI\").getInfo()\n",
        "\n",
        "        precip = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(point).sum().select(\"precipitation\") \\\n",
        "            .reduceRegion(ee.Reducer.mean(), point, 5000).get(\"precipitation\").getInfo()\n",
        "\n",
        "        lst_img = ee.ImageCollection(\"MODIS/061/MOD11A1\") \\\n",
        "            .filterDate(str(start_date), str(end_date)) \\\n",
        "            .filterBounds(point).select(\"LST_Day_1km\").mean()\n",
        "        lst = lst_img.multiply(0.02).subtract(273.15).reduceRegion(ee.Reducer.mean(), point, 1000).get(\"LST_Day_1km\").getInfo()\n",
        "\n",
        "        tree_img = ee.ImageCollection(\"MODIS/061/MOD44B\") \\\n",
        "            .filterBounds(point).select(\"Percent_Tree_Cover\").mean()\n",
        "        treecover = tree_img.reduceRegion(ee.Reducer.mean(), point, 250).get(\"Percent_Tree_Cover\").getInfo()\n",
        "\n",
        "        return [evi, ndvi, ndmi, lst, precip, treecover]\n",
        "    except:\n",
        "        return [None]*6\n",
        "\n",
        "# ------------------ Page 1 ------------------\n",
        "if page == \"Predict Forest Cover\":\n",
        "    st.header(\"üßê Forest Cover Prediction\")\n",
        "    st.info(f\"Selected {len(selected_gdf)} grid cells for prediction.\")\n",
        "\n",
        "    end_date = datetime.date.today()\n",
        "    start_date = end_date - datetime.timedelta(days=30)\n",
        "\n",
        "    features = []\n",
        "    for _, row in selected_gdf.iterrows():\n",
        "        lon, lat = row.geometry.centroid.x, row.geometry.centroid.y\n",
        "        feats = compute_features(lon, lat, start_date, end_date)\n",
        "        features.append((row[\"geometry\"], feats))\n",
        "\n",
        "    X = [[f[1][i] for i in [0, 2, 3, 4, 5]] if None not in f[1] else [0]*5 for f in features]\n",
        "    X_scaled = scaler.transform(np.array(X))\n",
        "    y_pred = model.predict(X_scaled)\n",
        "\n",
        "    param_data = [{\n",
        "        \"EVI\": round(f[1][0], 4) if f[1][0] is not None else \"N/A\",\n",
        "        \"NDMI\": round(f[1][2], 4) if f[1][2] is not None else \"N/A\",\n",
        "        \"LST\": round(f[1][3], 2) if f[1][3] is not None else \"N/A\",\n",
        "        \"Precip\": round(f[1][4], 2) if f[1][4] is not None else \"N/A\",\n",
        "        \"Tree Cover\": round(f[1][5], 1) if f[1][5] is not None else \"N/A\"\n",
        "    } for f in features]\n",
        "\n",
        "    result_map = folium.Map(location=[region.centroid().coordinates().getInfo()[1],\n",
        "                                      region.centroid().coordinates().getInfo()[0]], zoom_start=9.5)\n",
        "\n",
        "    for idx, (geom, pred) in enumerate(zip([f[0] for f in features], y_pred)):\n",
        "        tooltip_text = \"<br>\".join([f\"{k}: {v}\" for k, v in param_data[idx].items()])\n",
        "        tooltip_text += \"<br><b>Prediction</b>: \" + (\"Forest\" if pred == 0 else \"Deforested\")\n",
        "        fill = \"green\" if pred == 0 else \"red\"\n",
        "\n",
        "        folium.GeoJson(\n",
        "            geom,\n",
        "            tooltip=tooltip_text,\n",
        "            style_function=lambda x, fill_color=fill: {\n",
        "                \"fillColor\": fill_color,\n",
        "                \"color\": \"black\",\n",
        "                \"weight\": 0.5,\n",
        "                \"fillOpacity\": 0.6\n",
        "            }\n",
        "        ).add_to(result_map)\n",
        "\n",
        "    st.subheader(\"üó∫Ô∏è Predicted Forest Cover\")\n",
        "    st_folium(result_map, height=600, width=900)\n",
        "\n",
        "# ------------------ Page 2 ------------------\n",
        "if page == \"Timeline of Tree Cover\":\n",
        "    st.header(\"üìΩÔ∏è Animated Timeline of EVI (2016‚Äì2025)\")\n",
        "    years = list(range(2016, 2026))\n",
        "\n",
        "    def create_evi_image(year):\n",
        "        evi = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "            .filterDate(f\"{year}-01-01\", f\"{year}-12-31\") \\\n",
        "            .filterBounds(region) \\\n",
        "            .select(\"EVI\") \\\n",
        "            .mean() \\\n",
        "            .multiply(0.0001) \\\n",
        "            .clip(region)\n",
        "\n",
        "        return evi.visualize(min=0, max=0.8, palette=['#ffffcc', '#c2e699', '#78c679', '#31a354', '#006837']).set({'label': str(year)})\n",
        "\n",
        "    image_list = [create_evi_image(y) for y in years]\n",
        "    gif_collection = ee.ImageCollection(image_list)\n",
        "\n",
        "    gif_url = gif_collection.getVideoThumbURL({\n",
        "        'dimensions': 400,\n",
        "        'region': region.bounds(),\n",
        "        'framesPerSecond': 1,\n",
        "        'format': 'gif'\n",
        "    })\n",
        "\n",
        "    st.subheader(\"üéÆ EVI Animation Over Selected Region\")\n",
        "    st.image(gif_url, caption=\"üåø Animated EVI Change (2016‚Äì2025)\", width=400)\n",
        "\n",
        "    st.markdown(\"### üìä Yearly EVI Snapshots\")\n",
        "    thumbs = []\n",
        "    for year in years:\n",
        "        evi = ee.ImageCollection(\"MODIS/061/MOD13Q1\") \\\n",
        "            .filterDate(f\"{year}-01-01\", f\"{year}-12-31\") \\\n",
        "            .filterBounds(region).select(\"EVI\").mean() \\\n",
        "            .multiply(0.0001).clip(region)\n",
        "\n",
        "        vis = {\n",
        "            \"min\": 0,\n",
        "            \"max\": 0.8,\n",
        "            \"palette\": ['#ffffcc', '#c2e699', '#78c679', '#31a354', '#006837']\n",
        "        }\n",
        "\n",
        "        url = evi.visualize(**vis).getThumbURL({\n",
        "            \"region\": region.bounds().getInfo(),\n",
        "            \"dimensions\": 150,\n",
        "            \"format\": \"png\"\n",
        "        })\n",
        "        thumbs.append((year, url))\n",
        "\n",
        "    cols = st.columns(len(thumbs))\n",
        "    for i, (yr, url) in enumerate(thumbs):\n",
        "        with cols[i]:\n",
        "            st.image(url, caption=str(yr), use_container_width=True)\n",
        "\n",
        "# ------------------ Page 3 ------------------\n",
        "if page == \"Environmental Statistics\":\n",
        "    st.header(\"üìä Environmental Statistics\")\n",
        "\n",
        "    param_bands = {\n",
        "        \"NDVI\": (\"MODIS/061/MOD13Q1\", \"NDVI\", 250, 0.0001),\n",
        "        \"EVI\": (\"MODIS/061/MOD13Q1\", \"EVI\", 250, 0.0001),\n",
        "        \"Precipitation\": (\"UCSB-CHG/CHIRPS/DAILY\", \"precipitation\", 5000, 1),\n",
        "        \"LST (¬∞C)\": (\"MODIS/061/MOD11A1\", \"LST_Day_1km\", 1000, 0.02),\n",
        "        \"Tree Cover (%)\": (\"MODIS/061/MOD44B\", \"Percent_Tree_Cover\", 250, 1)\n",
        "    }\n",
        "\n",
        "    start_year = 2015\n",
        "    end_year = 2023\n",
        "    data = {k: [] for k in param_bands}\n",
        "    labels = []\n",
        "\n",
        "    for y in range(start_year, end_year + 1):\n",
        "        start = f\"{y}-01-01\"\n",
        "        end = f\"{y}-12-31\"\n",
        "        labels.append(str(y))\n",
        "        for name, (ic, band, scale, factor) in param_bands.items():\n",
        "            coll = ee.ImageCollection(ic).filterDate(start, end).filterBounds(region)\n",
        "            img = coll.select(band).mean()\n",
        "            if name == \"LST (¬∞C)\":\n",
        "                img = img.multiply(factor).subtract(273.15)\n",
        "            elif factor != 1:\n",
        "                img = img.multiply(factor)\n",
        "            val = img.reduceRegion(ee.Reducer.mean(), region, scale).get(band).getInfo()\n",
        "            data[name].append(val if val is not None else 0)\n",
        "\n",
        "    df = pd.DataFrame(data, index=labels)\n",
        "\n",
        "    # ---- Graph 1: EVI vs Precipitation (Normalized) ----\n",
        "    st.markdown(\"### üìà Normalized EVI vs Precipitation (2015‚Äì2023)\")\n",
        "    norm_df = df[['EVI', 'Precipitation']].copy()\n",
        "    norm_df = (norm_df - norm_df.min()) / (norm_df.max() - norm_df.min())\n",
        "\n",
        "    fig1, ax1 = plt.subplots(figsize=(6, 4))\n",
        "    ax1.plot(labels, norm_df['EVI'], marker='o', label=\"EVI\")\n",
        "    ax1.plot(labels, norm_df['Precipitation'], marker='s', label=\"Precipitation\")\n",
        "    ax1.set_ylabel(\"Normalized Value\")\n",
        "    ax1.set_xlabel(\"Year\")\n",
        "    ax1.set_title(\"EVI vs Precipitation\")\n",
        "    ax1.legend()\n",
        "    ax1.grid(True)\n",
        "    st.pyplot(fig1)\n",
        "\n",
        "    # ---- Graph 2: Correlation Matrix ----\n",
        "    st.markdown(\"### üìä Correlation Matrix\")\n",
        "    corr = df.corr()\n",
        "    fig2, ax2 = plt.subplots(figsize=(6, 4))\n",
        "    im = ax2.imshow(corr, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "    ax2.set_xticks(np.arange(len(corr.columns)))\n",
        "    ax2.set_yticks(np.arange(len(corr.columns)))\n",
        "    ax2.set_xticklabels(corr.columns, rotation=45, ha=\"right\")\n",
        "    ax2.set_yticklabels(corr.columns)\n",
        "    for i in range(len(corr.columns)):\n",
        "        for j in range(len(corr.columns)):\n",
        "            ax2.text(j, i, f\"{corr.iloc[i, j]:.2f}\", ha=\"center\", va=\"center\", color=\"black\")\n",
        "    fig2.colorbar(im, ax=ax2)\n",
        "    ax2.set_title(\"Correlation Matrix\")\n",
        "    st.pyplot(fig2)\n",
        "\n",
        "    # ---- Graph 3: Monthly Trends (Normalized) ----\n",
        "    st.markdown(\"### üìÖ Monthly Trends of EVI and Precipitation\")\n",
        "    monthly_df = pd.DataFrame(columns=[\"Month\", \"EVI\", \"Precipitation\"])\n",
        "\n",
        "    for month in range(1, 13):\n",
        "        start = f\"2023-{month:02d}-01\"\n",
        "        end = f\"2023-{month:02d}-28\"\n",
        "        evi = ee.ImageCollection(\"MODIS/061/MOD13Q1\").filterDate(start, end).filterBounds(region).select(\"EVI\").mean().multiply(0.0001)\n",
        "        precip = ee.ImageCollection(\"UCSB-CHG/CHIRPS/DAILY\").filterDate(start, end).filterBounds(region).select(\"precipitation\").sum()\n",
        "\n",
        "        evi_val = evi.reduceRegion(ee.Reducer.mean(), region, 250).get(\"EVI\").getInfo()\n",
        "        precip_val = precip.reduceRegion(ee.Reducer.mean(), region, 5000).get(\"precipitation\").getInfo()\n",
        "\n",
        "        monthly_df.loc[month - 1] = [month, evi_val or 0, precip_val or 0]\n",
        "\n",
        "    monthly_df[\"EVI_norm\"] = (monthly_df[\"EVI\"] - monthly_df[\"EVI\"].min()) / (monthly_df[\"EVI\"].max() - monthly_df[\"EVI\"].min())\n",
        "    monthly_df[\"Precip_norm\"] = (monthly_df[\"Precipitation\"] - monthly_df[\"Precipitation\"].min()) / (monthly_df[\"Precipitation\"].max() - monthly_df[\"Precipitation\"].min())\n",
        "\n",
        "    fig3, ax3 = plt.subplots(figsize=(6, 4))\n",
        "    ax3.plot(monthly_df[\"Month\"], monthly_df[\"EVI_norm\"], marker='o', label=\"EVI (Normalized)\")\n",
        "    ax3.plot(monthly_df[\"Month\"], monthly_df[\"Precip_norm\"], marker='s', label=\"Precipitation (Normalized)\")\n",
        "    ax3.set_xticks(range(1, 13))\n",
        "    ax3.set_xlabel(\"Month\")\n",
        "    ax3.set_ylabel(\"Normalized Value\")\n",
        "    ax3.set_title(\"Monthly EVI & Precipitation (2023)\")\n",
        "    ax3.grid(True)\n",
        "    ax3.legend()\n",
        "    st.pyplot(fig3)\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "YAmAjzGotq7B"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"app9.py\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(code9)"
      ],
      "metadata": {
        "id": "NLQ9wOR-6cmR"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dftk8xbH6gvH",
        "outputId": "d86253a8-ecea-4fdd-edbb-9b18c54ae11c"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.237.115.225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app9.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCDtwxzm6j03",
        "outputId": "7ba5cad9-ca72-4665-d3d7-c087cd460eb8"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K‚†á\u001b[1G\u001b[0K‚†è\u001b[1G\u001b[0K\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.115.225:8501\u001b[0m\n",
            "\u001b[0m\n",
            "your url is: https://forty-chefs-mate.loca.lt\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "code10 = '''\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "YtEQixWZ6led"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}